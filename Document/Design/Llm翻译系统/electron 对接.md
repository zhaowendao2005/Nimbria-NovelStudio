# ğŸ“‹ **LLM ç¿»è¯‘ç³»ç»Ÿ - Electron æœ¬åœ°é›†æˆè®¾è®¡æ–‡æ¡£ (v1.0)**

**ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¶é—´**: 2025å¹´10æœˆ20æ—¥  
**æ¶æ„æ¨¡å¼**: äº‹ä»¶é©±åŠ¨ + å¼ºç±»å‹ + Electron IPC  
**æ•°æ®åº“ç‰ˆæœ¬**: v1.2.0  
**è¿è¡Œç¯å¢ƒ**: çº¯æ¡Œé¢åº”ç”¨ï¼ˆæ— åç«¯æœåŠ¡å™¨ï¼‰

## ğŸ¯ **æ ¸å¿ƒè®¾è®¡åŸåˆ™**

1. âœ… **ä¸¥æ ¼äº‹ä»¶é©±åŠ¨**ï¼šæ‰€æœ‰å¼‚æ­¥æ“ä½œç«‹å³è¿”å›æ“ä½œIDï¼Œé€šè¿‡äº‹ä»¶åé¦ˆè¿›åº¦
2. âœ… **å¼ºç±»å‹çº¦æŸ**ï¼šä¸¥ç¦ `any`ï¼Œæ‰€æœ‰ç±»å‹å¿…é¡»æ˜¾å¼å®šä¹‰
3. âœ… **Electron æœ¬åœ°è¿›ç¨‹**ï¼šä¸»è¿›ç¨‹è¿è¡Œ LlmTranslateServiceï¼Œé€šè¿‡IPCä¸æ¸²æŸ“è¿›ç¨‹é€šä¿¡
4. âœ… **æœ¬åœ°æ•°æ®åº“**ï¼šä½¿ç”¨SQLiteå­˜å‚¨æ‰¹æ¬¡å’Œä»»åŠ¡æ•°æ®
5. âœ… **æœ¬åœ°æ–‡ä»¶æ“ä½œ**ï¼šé€šè¿‡ Electron Dialog API é€‰æ‹©æ–‡ä»¶è·¯å¾„
6. âœ… **ä¼˜é›…ä¸­æ–­å¤„ç†**ï¼šç¨‹åºç»ˆæ­¢æ—¶ï¼Œæ‰€æœ‰ `waiting` çŠ¶æ€çš„ä»»åŠ¡æ ‡è®°ä¸º `terminated`

---

## ğŸ“Š **æ•°æ®åº“ Schema è®¾è®¡ (v1.2.0)**

### **æ–‡ä»¶ä½ç½®**
```
src-electron/services/database-service/schema/versions/v1.2.0.schema.ts
```

### **å®Œæ•´ Schema å®šä¹‰**

```typescript
/**
 * Database Schema v1.2.0
 * æ·»åŠ  LLM Translate æ‰¹é‡ç¿»è¯‘ç³»ç»Ÿæ”¯æŒ
 */

import type { SchemaDefinition, TableDefinition } from '../base-schema'
import { PROJECT_TABLES as V1_1_0_TABLES } from './v1.1.0.schema'

// ========== LLM Translate ç›¸å…³è¡¨ ==========

const LLM_TRANSLATE_TABLES: TableDefinition[] = [
  {
    name: 'Llmtranslate_batches',
    sql: `CREATE TABLE IF NOT EXISTS Llmtranslate_batches (
      id TEXT PRIMARY KEY,                    -- æ‰¹æ¬¡ID (#20250115-001)
      status TEXT NOT NULL CHECK (status IN ('running', 'paused', 'completed', 'failed', 'terminated')),
      
      -- é…ç½®ä¿¡æ¯ (JSON åºåˆ—åŒ– TranslateConfig)
      config_json TEXT NOT NULL,
      
      -- ç»Ÿè®¡ä¿¡æ¯
      total_tasks INTEGER DEFAULT 0,
      completed_tasks INTEGER DEFAULT 0,
      failed_tasks INTEGER DEFAULT 0,
      throttled_tasks INTEGER DEFAULT 0,
      waiting_tasks INTEGER DEFAULT 0,
      unsent_tasks INTEGER DEFAULT 0,
      terminated_tasks INTEGER DEFAULT 0,     -- å› ç¨‹åºä¸­æ–­è€Œç»ˆæ­¢çš„ä»»åŠ¡æ•°
      
      -- æˆæœ¬ç»Ÿè®¡
      total_cost REAL DEFAULT 0,
      total_input_tokens INTEGER DEFAULT 0,
      total_output_tokens INTEGER DEFAULT 0,
      
      -- æ€§èƒ½ç»Ÿè®¡
      avg_time_per_task REAL DEFAULT 0,      -- å¹³å‡è€—æ—¶(ç§’)
      fastest_task_time REAL DEFAULT 0,      -- æœ€å¿«ä»»åŠ¡è€—æ—¶
      slowest_task_time REAL DEFAULT 0,      -- æœ€æ…¢ä»»åŠ¡è€—æ—¶
      estimated_completion_time DATETIME,     -- é¢„è®¡å®Œæˆæ—¶é—´
      
      -- æ—¶é—´æˆ³
      created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
      started_at DATETIME,                    -- å¼€å§‹æ‰§è¡Œæ—¶é—´
      completed_at DATETIME,                  -- å®Œæˆæ—¶é—´
      updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
    )`,
    indexes: [
      `CREATE INDEX IF NOT EXISTS idx_llmtranslate_batches_status ON Llmtranslate_batches(status)`,
      `CREATE INDEX IF NOT EXISTS idx_llmtranslate_batches_created ON Llmtranslate_batches(created_at DESC)`,
      `CREATE INDEX IF NOT EXISTS idx_llmtranslate_batches_updated ON Llmtranslate_batches(updated_at DESC)`
    ]
  },
  
  {
    name: 'Llmtranslate_tasks',
    sql: `CREATE TABLE IF NOT EXISTS Llmtranslate_tasks (
      id TEXT PRIMARY KEY,                    -- ä»»åŠ¡ID (#1250)
      batch_id TEXT NOT NULL,                 -- æ‰€å±æ‰¹æ¬¡
      
      -- ä»»åŠ¡çŠ¶æ€
      status TEXT NOT NULL CHECK (status IN ('unsent', 'waiting', 'throttled', 'error', 'completed', 'terminated')),
      
      -- å†…å®¹
      content TEXT NOT NULL,                  -- å¾…ç¿»è¯‘åŸæ–‡
      translation TEXT,                       -- ç¿»è¯‘ç»“æœ
      
      -- Token ä¿¡æ¯
      input_tokens INTEGER DEFAULT 0,        -- è¾“å…¥Tokenæ•°
      reply_tokens INTEGER DEFAULT 0,        -- å·²å›å¤Tokenæ•°
      predicted_tokens INTEGER DEFAULT 0,    -- é¢„è®¡å›å¤Tokenæ•°
      progress REAL DEFAULT 0,               -- è¿›åº¦ç™¾åˆ†æ¯” (0-100)
      
      -- æ—¶é—´ä¿¡æ¯
      sent_time DATETIME,                    -- å‘é€æ—¶é—´
      reply_time DATETIME,                   -- å›å¤å®Œæˆæ—¶é—´
      duration_ms INTEGER,                   -- è€—æ—¶(æ¯«ç§’)
      
      -- é”™è¯¯ä¿¡æ¯
      error_message TEXT,                    -- é”™è¯¯æ¶ˆæ¯
      error_type TEXT,                       -- é”™è¯¯ç±»å‹ (network/timeout/rate_limit/terminated/unknown)
      retry_count INTEGER DEFAULT 0,         -- é‡è¯•æ¬¡æ•°
      
      -- æˆæœ¬ä¿¡æ¯
      cost REAL DEFAULT 0,                   -- å•ä¸ªä»»åŠ¡æˆæœ¬
      
      -- å…ƒæ•°æ®
      metadata_json TEXT,                    -- æ‰©å±•å…ƒæ•°æ® (JSON)
      
      -- æ—¶é—´æˆ³
      created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
      updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
      
      FOREIGN KEY (batch_id) REFERENCES Llmtranslate_batches(id) ON DELETE CASCADE
    )`,
    indexes: [
      `CREATE INDEX IF NOT EXISTS idx_llmtranslate_tasks_batch ON Llmtranslate_tasks(batch_id)`,
      `CREATE INDEX IF NOT EXISTS idx_llmtranslate_tasks_status ON Llmtranslate_tasks(status)`,
      `CREATE INDEX IF NOT EXISTS idx_llmtranslate_tasks_created ON Llmtranslate_tasks(created_at)`,
      `CREATE INDEX IF NOT EXISTS idx_llmtranslate_tasks_progress ON Llmtranslate_tasks(progress)`,
      `CREATE INDEX IF NOT EXISTS idx_llmtranslate_tasks_error_type ON Llmtranslate_tasks(error_type)`
    ]
  },
  
  {
    name: 'Llmtranslate_stats',
    sql: `CREATE TABLE IF NOT EXISTS Llmtranslate_stats (
      batch_id TEXT PRIMARY KEY,
      
      -- æ€§èƒ½æŒ‡æ ‡
      fastest_task_id TEXT,                  -- æœ€å¿«ä»»åŠ¡ID
      fastest_time REAL,                     -- æœ€å¿«è€—æ—¶(ç§’)
      slowest_task_id TEXT,                  -- æœ€æ…¢ä»»åŠ¡ID
      slowest_time REAL,                     -- æœ€æ…¢è€—æ—¶(ç§’)
      avg_time REAL,                         -- å¹³å‡è€—æ—¶(ç§’)
      
      -- é”™è¯¯ç»Ÿè®¡
      network_errors INTEGER DEFAULT 0,      -- ç½‘ç»œé”™è¯¯æ¬¡æ•°
      timeout_errors INTEGER DEFAULT 0,      -- è¶…æ—¶é”™è¯¯æ¬¡æ•°
      rate_limit_errors INTEGER DEFAULT 0,   -- é™æµæ¬¡æ•°
      terminated_errors INTEGER DEFAULT 0,   -- ç¨‹åºä¸­æ–­æ¬¡æ•°
      unknown_errors INTEGER DEFAULT 0,      -- æœªçŸ¥é”™è¯¯æ¬¡æ•°
      
      -- æˆæœ¬åˆ†æ
      total_cost REAL DEFAULT 0,
      avg_cost_per_task REAL DEFAULT 0,
      total_input_tokens INTEGER DEFAULT 0,
      total_output_tokens INTEGER DEFAULT 0,
      
      -- æ—¶é—´åˆ†æ
      fast_completion_count INTEGER DEFAULT 0,    -- å¿«é€Ÿå®Œæˆ(< 1s)
      normal_completion_count INTEGER DEFAULT 0,  -- æ­£å¸¸å®Œæˆ(1-3s)
      slow_completion_count INTEGER DEFAULT 0,    -- ç¼“æ…¢å®Œæˆ(> 3s)
      
      -- æ›´æ–°æ—¶é—´
      updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
      
      FOREIGN KEY (batch_id) REFERENCES Llmtranslate_batches(id) ON DELETE CASCADE
    )`,
    indexes: []
  }
]

// ========== åˆå¹¶æ‰€æœ‰è¡¨ ==========

const PROJECT_TABLES_V1_2_0: TableDefinition[] = [
  ...V1_1_0_TABLES,
  ...LLM_TRANSLATE_TABLES
]

// ========== Schemaå¯¼å‡º ==========

export const PROJECT_SCHEMA_V1_2_0: SchemaDefinition = {
  version: '1.2.0',
  tables: PROJECT_TABLES_V1_2_0,
  description: 'Project database schema v1.2.0 - Added LLM Translate support'
}

export { PROJECT_TABLES_V1_2_0 as PROJECT_TABLES }
```

---

## ğŸ”§ **ç±»å‹å®šä¹‰ (å¼ºç±»å‹)**

### **æ–‡ä»¶ä½ç½®**
```
src-electron/services/llm-translate-service/types.ts
```

### **å®Œæ•´ç±»å‹å®šä¹‰**

```typescript
/**
 * LLM Translate Service ç±»å‹å®šä¹‰
 * ä¸¥æ ¼å¼ºç±»å‹ï¼Œç¦æ­¢ any
 */

// ========== åŸºç¡€ç±»å‹ ==========

export type TaskStatus = 'unsent' | 'waiting' | 'throttled' | 'error' | 'completed' | 'terminated'
export type BatchStatus = 'running' | 'paused' | 'completed' | 'failed' | 'terminated'
export type ChunkStrategy = 'line' | 'token'
export type ReplyMode = 'predicted' | 'equivalent'
export type ErrorType = 'network' | 'timeout' | 'rate_limit' | 'terminated' | 'unknown'

// ========== é…ç½®ç±»å‹ ==========

export interface TranslateConfig {
  inputSource: 'file' | 'text'
  content: string
  filePath: string
  systemPrompt: string
  chunkStrategy: ChunkStrategy
  chunkSize: number
  concurrency: number
  replyMode: ReplyMode
  predictedTokens: number
  modelId: string
  outputDir: string
}

// ========== æ‰¹æ¬¡ç±»å‹ ==========

export interface Batch {
  id: string
  status: BatchStatus
  configJson: string                         // TranslateConfig çš„ JSON åºåˆ—åŒ–
  totalTasks: number
  completedTasks: number
  failedTasks: number
  throttledTasks: number
  waitingTasks: number
  unsentTasks: number
  terminatedTasks: number
  totalCost: number
  totalInputTokens: number
  totalOutputTokens: number
  avgTimePerTask: number
  fastestTaskTime: number
  slowestTaskTime: number
  estimatedCompletionTime: string | null
  createdAt: string
  startedAt: string | null
  completedAt: string | null
  updatedAt: string
}

export interface BatchCreateRequest {
  config: TranslateConfig
  content: string
}

export interface BatchStats {
  totalTasks: number
  completedTasks: number
  failedTasks: number
  successRate: number
  totalCost: number
  estimatedTime: number
}

// ========== ä»»åŠ¡ç±»å‹ ==========

export interface Task {
  id: string
  batchId: string
  status: TaskStatus
  content: string
  translation: string | null
  inputTokens: number
  replyTokens: number
  predictedTokens: number
  progress: number
  sentTime: string | null
  replyTime: string | null
  durationMs: number | null
  errorMessage: string | null
  errorType: ErrorType | null
  retryCount: number
  cost: number
  metadataJson: string | null
  createdAt: string
  updatedAt: string
}

export interface TaskCreateData {
  id: string
  batchId: string
  content: string
  predictedTokens: number
}

// ========== ç»Ÿè®¡ç±»å‹ ==========

export interface TranslateStats {
  batchId: string
  fastestTaskId: string | null
  fastestTime: number | null
  slowestTaskId: string | null
  slowestTime: number | null
  avgTime: number
  networkErrors: number
  timeoutErrors: number
  rateLimitErrors: number
  terminatedErrors: number
  unknownErrors: number
  totalCost: number
  avgCostPerTask: number
  totalInputTokens: number
  totalOutputTokens: number
  fastCompletionCount: number
  normalCompletionCount: number
  slowCompletionCount: number
  updatedAt: string
}

// ========== äº‹ä»¶ç±»å‹ ==========

export interface BatchCreateStartEvent {
  batchId: string
  totalTasks: number
}

export interface BatchCreatedEvent {
  batchId: string
  batch: Batch
  tasks: Task[]
}

export interface BatchCreateErrorEvent {
  batchId: string
  error: string
}

export interface TaskSubmitStartEvent {
  batchId: string
  taskIds: string[]
}

export interface TaskSubmittedEvent {
  batchId: string
  taskId: string
  sentTime: string
}

export interface TaskProgressEvent {
  batchId: string
  taskId: string
  replyTokens: number
  progress: number
  chunk: string
}

export interface TaskCompleteEvent {
  batchId: string
  taskId: string
  translation: string
  totalTokens: number
  durationMs: number
  cost: number
}

export interface TaskErrorEvent {
  batchId: string
  taskId: string
  errorType: ErrorType
  errorMessage: string
}

export interface BatchProgressEvent {
  batchId: string
  completedTasks: number
  totalTasks: number
  progress: number
}

export interface BatchCompleteEvent {
  batchId: string
  stats: BatchStats
}

export interface BatchPauseEvent {
  batchId: string
  pausedAt: string
}

export interface BatchResumeEvent {
  batchId: string
  resumedAt: string
}

export interface ExportStartEvent {
  exportId: string
  batchId: string
  format: 'txt' | 'csv' | 'json'
  taskCount: number
}

export interface ExportCompleteEvent {
  exportId: string
  filePath: string
  fileSize: number
}

export interface ExportErrorEvent {
  exportId: string
  error: string
}

// ========== å¯¼å‡ºé€‰é¡¹ ==========

export interface ExportOptions {
  format: 'txt' | 'csv' | 'json'
  includeFailed: boolean
  includeUnsent: boolean
  includeMetadata: boolean
  includeStats: boolean
  outputDir: string
  fileName: string
}

// ========== API å“åº”ç±»å‹ ==========

export interface ApiResponse<T> {
  success: boolean
  data?: T
  error?: string
}

export interface BatchListResponse {
  batches: Batch[]
  total: number
}

export interface TaskListResponse {
  tasks: Task[]
  total: number
}
```

---

## ğŸ—ï¸ **åç«¯æœåŠ¡æ¶æ„**

### **1. LlmTranslateService (ä¸»æœåŠ¡ç±»)**

**æ–‡ä»¶ä½ç½®**: `src-electron/services/llm-translate-service/llm-translate-service.ts`

```typescript
/**
 * LLM ç¿»è¯‘ä¸»æœåŠ¡ç±» - Electron ä¸»è¿›ç¨‹æœ¬åœ°æœåŠ¡
 * 
 * æ¶æ„èŒè´£ï¼š
 * - ç®¡ç†æ‰¹æ¬¡å’Œä»»åŠ¡çš„ç”Ÿå‘½å‘¨æœŸ
 * - ä¸ SQLite æ•°æ®åº“äº¤äº’ï¼ˆæœ¬åœ°å­˜å‚¨ï¼‰
 * - é›†æˆ LlmChatService è¿›è¡Œç¿»è¯‘ï¼ˆæœ¬åœ°LLMè°ƒç”¨ï¼‰
 * - é€šè¿‡äº‹ä»¶é©±åŠ¨å‘ IPC å±‚å¹¿æ’­è¿›åº¦åé¦ˆ
 * 
 * âš ï¸ è¿è¡Œåœ¨ Electron ä¸»è¿›ç¨‹ï¼Œä¸æ¸²æŸ“è¿›ç¨‹é€šè¿‡ IPC é€šä¿¡
 * âš ï¸ æ— ç½‘ç»œè¯·æ±‚ï¼Œæ— åç«¯æœåŠ¡å™¨ä¾èµ–
 */

import { EventEmitter } from 'events'
import { nanoid } from 'nanoid'
import type { ProjectDatabase } from '../database-service/project-database'
import type { LlmChatService } from '../llm-chat-service/llm-chat-service'
import { BatchManager } from './batch-manager'
import { TaskManager } from './task-manager'
import { TranslationExecutor } from './translation-executor'
import { ExportService } from './export-service'
import type {
  TranslateConfig,
  Batch,
  Task,
  BatchCreateStartEvent,
  BatchCreatedEvent,
  BatchCreateErrorEvent,
  TaskSubmitStartEvent,
  TaskSubmittedEvent,
  TaskProgressEvent,
  TaskCompleteEvent,
  TaskErrorEvent,
  BatchProgressEvent,
  BatchCompleteEvent,
  BatchPauseEvent,
  BatchResumeEvent,
  ExportStartEvent,
  ExportCompleteEvent,
  ExportErrorEvent,
  ExportOptions,
  BatchListResponse,
  TaskListResponse
} from './types'

export class LlmTranslateService extends EventEmitter {
  private projectDatabase: ProjectDatabase | null = null
  private llmChatService: LlmChatService
  private batchManager: BatchManager
  private taskManager: TaskManager
  private translationExecutor: TranslationExecutor
  private exportService: ExportService
  private activeBatches: Map<string, Batch> = new Map()

  constructor(llmChatService: LlmChatService) {
    super()
    this.llmChatService = llmChatService
    this.batchManager = new BatchManager(this)
    this.taskManager = new TaskManager(this)
    this.translationExecutor = new TranslationExecutor(this, llmChatService)
    this.exportService = new ExportService(this)
  }

  /**
   * åˆå§‹åŒ–æœåŠ¡ï¼ˆè®¾ç½®é¡¹ç›®æ•°æ®åº“ï¼‰
   */
  async initialize(projectPath: string, projectDatabase: ProjectDatabase): Promise<void> {
    console.log('ğŸš€ [LlmTranslateService] åˆå§‹åŒ–æœåŠ¡...')
    this.projectDatabase = projectDatabase
    
    // ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰æ‰¹æ¬¡
    await this.loadBatches()
    
    // æ£€æŸ¥ç¨‹åºä¸­æ–­çš„ä»»åŠ¡ï¼Œæ ‡è®°ä¸º terminated
    await this.handleTerminatedTasks()
    
    console.log('âœ… [LlmTranslateService] æœåŠ¡åˆå§‹åŒ–å®Œæˆ')
  }

  /**
   * å¤„ç†å› ç¨‹åºç»ˆæ­¢è€Œä¸­æ–­çš„ä»»åŠ¡
   * å°†æ‰€æœ‰ status = 'waiting' çš„ä»»åŠ¡æ ‡è®°ä¸º 'terminated'
   */
  private async handleTerminatedTasks(): Promise<void> {
    if (!this.projectDatabase) return

    const terminatedTasks = await this.projectDatabase.query<Task>(
      `UPDATE Llmtranslate_tasks 
       SET status = 'terminated', 
           error_type = 'terminated',
           error_message = 'ç¨‹åºå¼‚å¸¸ç»ˆæ­¢ï¼Œä»»åŠ¡æœªå®Œæˆ',
           updated_at = CURRENT_TIMESTAMP
       WHERE status = 'waiting'
       RETURNING *`
    )

    if (terminatedTasks.length > 0) {
      console.log(`âš ï¸ [LlmTranslateService] å‘ç° ${terminatedTasks.length} ä¸ªä¸­æ–­ä»»åŠ¡ï¼Œå·²æ ‡è®°ä¸º terminated`)
      
      // æ›´æ–°æ‰¹æ¬¡ç»Ÿè®¡
      for (const task of terminatedTasks) {
        await this.updateBatchStats(task.batchId)
      }
    }
  }

  /**
   * åˆ›å»ºæ–°æ‰¹æ¬¡
   * ç«‹å³è¿”å› batchIdï¼Œé€šè¿‡äº‹ä»¶åé¦ˆåˆ›å»ºè¿›åº¦
   */
  async createBatch(config: TranslateConfig, content: string): Promise<string> {
    const batchId = `#${Date.now().toString().slice(-8)}`
    
    // âœ… ç«‹å³å‘å°„å¼€å§‹äº‹ä»¶
    this.emit('batch:create-start', {
      batchId,
      totalTasks: 0  // å°šæœªåˆ†ç‰‡ï¼Œå…ˆä¸º 0
    } as BatchCreateStartEvent)
    
    // âœ… å¼‚æ­¥å¤„ç†ï¼Œä¸é˜»å¡è¿”å›
    this.createBatchAsync(batchId, config, content)
    
    return batchId
  }

  /**
   * å¼‚æ­¥åˆ›å»ºæ‰¹æ¬¡ï¼ˆåˆ†ç‰‡ã€å…¥åº“ï¼‰
   */
  private async createBatchAsync(
    batchId: string,
    config: TranslateConfig,
    content: string
  ): Promise<void> {
    try {
      if (!this.projectDatabase) {
        throw new Error('Project database not initialized')
      }

      // 1. æ ¹æ®åˆ†ç‰‡ç­–ç•¥åˆ†å‰²å†…å®¹
      const chunks = this.chunkContent(content, config.chunkStrategy, config.chunkSize)
      const totalTasks = chunks.length

      console.log(`ğŸ“¦ [LlmTranslateService] æ‰¹æ¬¡ ${batchId} - åˆ†å‰²ä¸º ${totalTasks} ä¸ªä»»åŠ¡`)

      // 2. åˆ›å»ºæ‰¹æ¬¡è®°å½•
      const batch: Batch = {
        id: batchId,
        status: 'running',
        configJson: JSON.stringify(config),
        totalTasks,
        completedTasks: 0,
        failedTasks: 0,
        throttledTasks: 0,
        waitingTasks: 0,
        unsentTasks: totalTasks,
        terminatedTasks: 0,
        totalCost: 0,
        totalInputTokens: 0,
        totalOutputTokens: 0,
        avgTimePerTask: 0,
        fastestTaskTime: 0,
        slowestTaskTime: 0,
        estimatedCompletionTime: null,
        createdAt: new Date().toISOString(),
        startedAt: null,
        completedAt: null,
        updatedAt: new Date().toISOString()
      }

      await this.projectDatabase.run(
        `INSERT INTO Llmtranslate_batches (
          id, status, config_json, total_tasks, unsent_tasks, created_at, updated_at
        ) VALUES (?, ?, ?, ?, ?, ?, ?)`,
        [batch.id, batch.status, batch.configJson, batch.totalTasks, batch.unsentTasks, batch.createdAt, batch.updatedAt]
      )

      // 3. åˆ›å»ºä»»åŠ¡è®°å½•
      const tasks: Task[] = []
      for (let i = 0; i < chunks.length; i++) {
        const taskId = `${batchId}-${i + 1}`
        const task: Task = {
          id: taskId,
          batchId: batch.id,
          status: 'unsent',
          content: chunks[i],
          translation: null,
          inputTokens: this.estimateTokens(chunks[i]),
          replyTokens: 0,
          predictedTokens: config.predictedTokens,
          progress: 0,
          sentTime: null,
          replyTime: null,
          durationMs: null,
          errorMessage: null,
          errorType: null,
          retryCount: 0,
          cost: 0,
          metadataJson: null,
          createdAt: new Date().toISOString(),
          updatedAt: new Date().toISOString()
        }

        await this.projectDatabase.run(
          `INSERT INTO Llmtranslate_tasks (
            id, batch_id, status, content, input_tokens, predicted_tokens, 
            progress, retry_count, cost, created_at, updated_at
          ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)`,
          [
            task.id, task.batchId, task.status, task.content, task.inputTokens,
            task.predictedTokens, task.progress, task.retryCount, task.cost,
            task.createdAt, task.updatedAt
          ]
        )

        tasks.push(task)
      }

      // 4. åˆ›å»ºç»Ÿè®¡è®°å½•
      await this.projectDatabase.run(
        `INSERT INTO Llmtranslate_stats (batch_id, updated_at) VALUES (?, ?)`,
        [batch.id, new Date().toISOString()]
      )

      // 5. ç¼“å­˜æ‰¹æ¬¡
      this.activeBatches.set(batchId, batch)

      // âœ… å‘å°„åˆ›å»ºå®Œæˆäº‹ä»¶
      this.emit('batch:created', {
        batchId,
        batch,
        tasks
      } as BatchCreatedEvent)

      console.log(`âœ… [LlmTranslateService] æ‰¹æ¬¡ ${batchId} åˆ›å»ºæˆåŠŸ`)

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error)
      console.error(`âŒ [LlmTranslateService] æ‰¹æ¬¡ ${batchId} åˆ›å»ºå¤±è´¥:`, errorMessage)
      
      // âœ… å‘å°„é”™è¯¯äº‹ä»¶
      this.emit('batch:create-error', {
        batchId,
        error: errorMessage
      } as BatchCreateErrorEvent)
    }
  }

  /**
   * åˆ†ç‰‡å†…å®¹
   * æŒ‰è¡Œå®Œæ•´åˆ†ç‰‡ï¼Œä¸åœ¨è¡Œä¸­é—´æˆªæ–­
   */
  private chunkContent(content: string, strategy: ChunkStrategy, chunkSize: number): string[] {
    const lines = content.split('\n')
    const chunks: string[] = []

    if (strategy === 'line') {
      // æŒ‰è¡Œæ•°åˆ†ç‰‡
      for (let i = 0; i < lines.length; i += chunkSize) {
        chunks.push(lines.slice(i, i + chunkSize).join('\n'))
      }
    } else {
      // æŒ‰ Token åˆ†ç‰‡ï¼ˆä½†ä¿æŒè¡Œå®Œæ•´ï¼‰
      let currentChunk: string[] = []
      let currentTokens = 0

      for (const line of lines) {
        const lineTokens = this.estimateTokens(line)
        
        if (currentTokens + lineTokens > chunkSize && currentChunk.length > 0) {
          // å½“å‰å—å·²æ»¡ï¼Œä¿å­˜å¹¶å¼€å§‹æ–°å—
          chunks.push(currentChunk.join('\n'))
          currentChunk = [line]
          currentTokens = lineTokens
        } else {
          currentChunk.push(line)
          currentTokens += lineTokens
        }
      }

      // ä¿å­˜æœ€åä¸€ä¸ªå—
      if (currentChunk.length > 0) {
        chunks.push(currentChunk.join('\n'))
      }
    }

    return chunks
  }

  /**
   * ä¼°ç®— Token æ•°ï¼ˆç®€å•ç®—æ³•ï¼šå­—ç¬¦æ•° / 4ï¼‰
   */
  private estimateTokens(text: string): number {
    return Math.ceil(text.length / 4)
  }

  /**
   * æäº¤ä»»åŠ¡åˆ° LLMï¼ˆæ‰¹é‡ï¼‰
   * ç«‹å³è¿”å› submissionIdï¼Œé€šè¿‡äº‹ä»¶åé¦ˆæ¯ä¸ªä»»åŠ¡çš„æäº¤çŠ¶æ€
   */
  async submitTasks(batchId: string, taskIds: string[]): Promise<string> {
    const submissionId = `sub_${Date.now()}_${nanoid(6)}`
    
    // âœ… å‘å°„æäº¤å¼€å§‹äº‹ä»¶
    this.emit('task:submit-start', {
      batchId,
      taskIds
    } as TaskSubmitStartEvent)
    
    // âœ… å¼‚æ­¥æäº¤
    this.submitTasksAsync(batchId, taskIds, submissionId)
    
    return submissionId
  }

  /**
   * å¼‚æ­¥æäº¤ä»»åŠ¡
   */
  private async submitTasksAsync(
    batchId: string,
    taskIds: string[],
    submissionId: string
  ): Promise<void> {
    if (!this.projectDatabase) return

    const batch = await this.getBatch(batchId)
    if (!batch) {
      console.error(`âŒ [LlmTranslateService] æ‰¹æ¬¡ ${batchId} ä¸å­˜åœ¨`)
      return
    }

    const config: TranslateConfig = JSON.parse(batch.configJson)
    const concurrency = config.concurrency

    // ä½¿ç”¨ç¿»è¯‘æ‰§è¡Œå™¨å¤„ç†ä»»åŠ¡é˜Ÿåˆ—
    await this.translationExecutor.executeTasks(batchId, taskIds, config, concurrency)
  }

  /**
   * è·å–æ‰¹æ¬¡åˆ—è¡¨
   */
  async getBatches(): Promise<BatchListResponse> {
    if (!this.projectDatabase) {
      throw new Error('Project database not initialized')
    }

    const batches = await this.projectDatabase.query<Batch>(
      `SELECT * FROM Llmtranslate_batches ORDER BY created_at DESC`
    )

    return {
      batches,
      total: batches.length
    }
  }

  /**
   * è·å–å•ä¸ªæ‰¹æ¬¡
   */
  async getBatch(batchId: string): Promise<Batch | null> {
    if (!this.projectDatabase) return null

    const batches = await this.projectDatabase.query<Batch>(
      `SELECT * FROM Llmtranslate_batches WHERE id = ?`,
      [batchId]
    )

    return batches[0] || null
  }

  /**
   * è·å–æ‰¹æ¬¡çš„ä»»åŠ¡åˆ—è¡¨
   */
  async getTasks(batchId: string): Promise<TaskListResponse> {
    if (!this.projectDatabase) {
      throw new Error('Project database not initialized')
    }

    const tasks = await this.projectDatabase.query<Task>(
      `SELECT * FROM Llmtranslate_tasks WHERE batch_id = ? ORDER BY created_at ASC`,
      [batchId]
    )

    return {
      tasks,
      total: tasks.length
    }
  }

  /**
   * è·å–å•ä¸ªä»»åŠ¡
   */
  async getTask(taskId: string): Promise<Task | null> {
    if (!this.projectDatabase) return null

    const tasks = await this.projectDatabase.query<Task>(
      `SELECT * FROM Llmtranslate_tasks WHERE id = ?`,
      [taskId]
    )

    return tasks[0] || null
  }

  /**
   * æš‚åœæ‰¹æ¬¡
   */
  async pauseBatch(batchId: string): Promise<void> {
    if (!this.projectDatabase) return

    await this.projectDatabase.run(
      `UPDATE Llmtranslate_batches SET status = 'paused', updated_at = CURRENT_TIMESTAMP WHERE id = ?`,
      [batchId]
    )

    this.translationExecutor.pauseBatch(batchId)

    this.emit('batch:paused', {
      batchId,
      pausedAt: new Date().toISOString()
    } as BatchPauseEvent)
  }

  /**
   * æ¢å¤æ‰¹æ¬¡
   */
  async resumeBatch(batchId: string): Promise<void> {
    if (!this.projectDatabase) return

    await this.projectDatabase.run(
      `UPDATE Llmtranslate_batches SET status = 'running', updated_at = CURRENT_TIMESTAMP WHERE id = ?`,
      [batchId]
    )

    this.translationExecutor.resumeBatch(batchId)

    this.emit('batch:resumed', {
      batchId,
      resumedAt: new Date().toISOString()
    } as BatchResumeEvent)
  }

  /**
   * å¯¼å‡ºæ‰¹æ¬¡ç»“æœ
   * é€šè¿‡ Electron Dialog é€‰æ‹©è·¯å¾„
   */
  async exportBatch(batchId: string, options: ExportOptions): Promise<string> {
    const exportId = `export_${Date.now()}_${nanoid(6)}`
    
    this.emit('export:start', {
      exportId,
      batchId,
      format: options.format,
      taskCount: 0  // ç¨åæ›´æ–°
    } as ExportStartEvent)
    
    this.exportBatchAsync(exportId, batchId, options)
    
    return exportId
  }

  /**
   * å¼‚æ­¥å¯¼å‡º
   */
  private async exportBatchAsync(
    exportId: string,
    batchId: string,
    options: ExportOptions
  ): Promise<void> {
    try {
      const result = await this.exportService.export(batchId, options)
      
      this.emit('export:complete', {
        exportId,
        filePath: result.filePath,
        fileSize: result.fileSize
      } as ExportCompleteEvent)
      
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error)
      this.emit('export:error', {
        exportId,
        error: errorMessage
      } as ExportErrorEvent)
    }
  }

  /**
   * é‡è¯•å¤±è´¥ä»»åŠ¡
   */
  async retryFailedTasks(batchId: string): Promise<string> {
    if (!this.projectDatabase) {
      throw new Error('Project database not initialized')
    }

    const failedTasks = await this.projectDatabase.query<Task>(
      `SELECT id FROM Llmtranslate_tasks 
       WHERE batch_id = ? AND status IN ('error', 'throttled', 'terminated')`,
      [batchId]
    )

    const taskIds = failedTasks.map((t: Task) => t.id)
    
    if (taskIds.length === 0) {
      throw new Error('æ²¡æœ‰éœ€è¦é‡è¯•çš„ä»»åŠ¡')
    }

    // é‡ç½®ä»»åŠ¡çŠ¶æ€
    await this.projectDatabase.run(
      `UPDATE Llmtranslate_tasks 
       SET status = 'unsent', 
           error_message = NULL, 
           error_type = NULL, 
           retry_count = retry_count + 1,
           updated_at = CURRENT_TIMESTAMP
       WHERE id IN (${taskIds.map(() => '?').join(',')})`,
      taskIds
    )

    // é‡æ–°æäº¤
    return await this.submitTasks(batchId, taskIds)
  }

  /**
   * æ›´æ–°æ‰¹æ¬¡ç»Ÿè®¡
   */
  private async updateBatchStats(batchId: string): Promise<void> {
    if (!this.projectDatabase) return

    const stats = await this.projectDatabase.query<{
      completed: number
      failed: number
      throttled: number
      waiting: number
      unsent: number
      terminated: number
    }>(
      `SELECT 
        SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) as completed,
        SUM(CASE WHEN status = 'error' THEN 1 ELSE 0 END) as failed,
        SUM(CASE WHEN status = 'throttled' THEN 1 ELSE 0 END) as throttled,
        SUM(CASE WHEN status = 'waiting' THEN 1 ELSE 0 END) as waiting,
        SUM(CASE WHEN status = 'unsent' THEN 1 ELSE 0 END) as unsent,
        SUM(CASE WHEN status = 'terminated' THEN 1 ELSE 0 END) as terminated
       FROM Llmtranslate_tasks WHERE batch_id = ?`,
      [batchId]
    )

    if (stats[0]) {
      await this.projectDatabase.run(
        `UPDATE Llmtranslate_batches 
         SET completed_tasks = ?, 
             failed_tasks = ?, 
             throttled_tasks = ?, 
             waiting_tasks = ?, 
             unsent_tasks = ?,
             terminated_tasks = ?,
             updated_at = CURRENT_TIMESTAMP
         WHERE id = ?`,
        [
          stats[0].completed,
          stats[0].failed,
          stats[0].throttled,
          stats[0].waiting,
          stats[0].unsent,
          stats[0].terminated,
          batchId
        ]
      )
    }
  }

  /**
   * åŠ è½½æ‰€æœ‰æ‰¹æ¬¡
   */
  private async loadBatches(): Promise<void> {
    if (!this.projectDatabase) return

    const batches = await this.projectDatabase.query<Batch>(
      `SELECT * FROM Llmtranslate_batches ORDER BY created_at DESC LIMIT 100`
    )

    this.activeBatches.clear()
    for (const batch of batches) {
      this.activeBatches.set(batch.id, batch)
    }

    console.log(`ğŸ“š [LlmTranslateService] åŠ è½½äº† ${batches.length} ä¸ªæ‰¹æ¬¡`)
  }

  /**
   * è·å–é¡¹ç›®æ•°æ®åº“ï¼ˆä¾›å­æ¨¡å—ä½¿ç”¨ï¼‰
   */
  getProjectDatabase(): ProjectDatabase | null {
    return this.projectDatabase
  }
}
```

---

## ğŸ¯ **ç¿»è¯‘æ‰§è¡Œå™¨ (TranslationExecutor)**

**æ–‡ä»¶ä½ç½®**: `src-electron/services/llm-translate-service/translation-executor.ts`

```typescript
/**
 * ç¿»è¯‘æ‰§è¡Œå™¨ - Electron ä¸»è¿›ç¨‹ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†å™¨
 * 
 * èŒè´£ï¼š
 * - ç®¡ç†ä»»åŠ¡é˜Ÿåˆ—ï¼ˆFIFOï¼‰
 * - å¹¶å‘æ§åˆ¶ï¼ˆé™åˆ¶åŒæ—¶æ‰§è¡Œçš„ä»»åŠ¡æ•°ï¼‰
 * - ä¸ LlmChatService äº¤äº’è°ƒç”¨æœ¬åœ°LLMè¿›è¡Œç¿»è¯‘
 * - ç›‘å¬æµå¼å“åº”å¹¶å¹¿æ’­è¿›åº¦äº‹ä»¶
 * - é”™è¯¯æ•è·å’Œé‡è¯•é€»è¾‘
 * 
 * âš ï¸ æ‰€æœ‰æ“ä½œéƒ½åœ¨ä¸»è¿›ç¨‹æœ¬åœ°å®Œæˆï¼Œæ— å¤–éƒ¨ç½‘ç»œè°ƒç”¨
 */

import type { LlmTranslateService } from './llm-translate-service'
import type { LlmChatService } from '../llm-chat-service/llm-chat-service'
import type { TranslateConfig, Task, TaskStatus, ErrorType } from './types'

export class TranslationExecutor {
  private llmTranslateService: LlmTranslateService
  private llmChatService: LlmChatService
  private taskQueues: Map<string, string[]> = new Map()  // batchId -> taskIds[]
  private pausedBatches: Set<string> = new Set()
  private activeTaskCount: Map<string, number> = new Map()  // batchId -> count

  constructor(llmTranslateService: LlmTranslateService, llmChatService: LlmChatService) {
    this.llmTranslateService = llmTranslateService
    this.llmChatService = llmChatService
  }

  /**
   * æ‰§è¡Œä»»åŠ¡é˜Ÿåˆ—
   * ä½¿ç”¨å¹¶å‘æ§åˆ¶ï¼Œé™åˆ¶åŒæ—¶æ‰§è¡Œçš„ä»»åŠ¡æ•°
   */
  async executeTasks(
    batchId: string,
    taskIds: string[],
    config: TranslateConfig,
    concurrency: number
  ): Promise<void> {
    this.taskQueues.set(batchId, [...taskIds])
    this.activeTaskCount.set(batchId, 0)

    console.log(`ğŸ¬ [TranslationExecutor] å¼€å§‹æ‰§è¡Œæ‰¹æ¬¡ ${batchId}ï¼Œå…± ${taskIds.length} ä¸ªä»»åŠ¡ï¼Œå¹¶å‘: ${concurrency}`)

    // å¯åŠ¨å¹¶å‘ä»»åŠ¡
    const workers: Promise<void>[] = []
    for (let i = 0; i < Math.min(concurrency, taskIds.length); i++) {
      workers.push(this.worker(batchId, config))
    }

    await Promise.all(workers)

    console.log(`âœ… [TranslationExecutor] æ‰¹æ¬¡ ${batchId} æ‰§è¡Œå®Œæˆ`)
  }

  /**
   * å·¥ä½œçº¿ç¨‹ï¼šä¸æ–­ä»é˜Ÿåˆ—å–ä»»åŠ¡å¹¶æ‰§è¡Œ
   */
  private async worker(batchId: string, config: TranslateConfig): Promise<void> {
    while (true) {
      // æ£€æŸ¥æ˜¯å¦æš‚åœ
      if (this.pausedBatches.has(batchId)) {
        console.log(`â¸ï¸ [TranslationExecutor] æ‰¹æ¬¡ ${batchId} å·²æš‚åœï¼Œå·¥ä½œçº¿ç¨‹é€€å‡º`)
        break
      }

      // ä»é˜Ÿåˆ—å–ä»»åŠ¡
      const queue = this.taskQueues.get(batchId)
      if (!queue || queue.length === 0) {
        break  // é˜Ÿåˆ—ç©ºäº†ï¼Œé€€å‡º
      }

      const taskId = queue.shift()
      if (!taskId) break

      // æ‰§è¡Œä»»åŠ¡
      await this.executeTask(batchId, taskId, config)

      // ç­‰å¾…é—´éš”ï¼ˆé˜²æ­¢é™æµï¼‰
      await this.delay(1000 / config.concurrency * 60)  // åŸºäºå¹¶å‘æ•°è®¡ç®—é—´éš”
    }
  }

  /**
   * æ‰§è¡Œå•ä¸ªä»»åŠ¡
   */
  private async executeTask(batchId: string, taskId: string, config: TranslateConfig): Promise<void> {
    const projectDb = this.llmTranslateService.getProjectDatabase()
    if (!projectDb) return

    try {
      // 1. è·å–ä»»åŠ¡
      const task = await this.llmTranslateService.getTask(taskId)
      if (!task) {
        throw new Error(`Task ${taskId} not found`)
      }

      // 2. æ›´æ–°çŠ¶æ€ä¸º waiting
      await projectDb.run(
        `UPDATE Llmtranslate_tasks 
         SET status = 'waiting', sent_time = CURRENT_TIMESTAMP, updated_at = CURRENT_TIMESTAMP 
         WHERE id = ?`,
        [taskId]
      )

      this.llmTranslateService.emit('task:submitted', {
        batchId,
        taskId,
        sentTime: new Date().toISOString()
      })

      // 3. è°ƒç”¨ LLM API è¿›è¡Œç¿»è¯‘ï¼ˆä½¿ç”¨ LlmChatServiceï¼‰
      const startTime = Date.now()
      let translationResult = ''
      let replyTokens = 0

      // åˆ›å»ºä¸´æ—¶å¯¹è¯
      const conversationId = await this.llmChatService.createConversation(config.modelId, {
        temperature: 0.7,
        maxTokens: config.predictedTokens
      })

      // ç›‘å¬æµå¼å“åº”
      const messageId = await this.llmChatService.sendMessage(conversationId, 
        `${config.systemPrompt}\n\n${task.content}`
      )

      // é€šè¿‡äº‹ä»¶ç›‘å¬æµå¼è¿›åº¦
      const chunkHandler = (data: { messageId: string; chunk: string; conversationId: string }) => {
        if (data.conversationId === conversationId && data.messageId === messageId) {
          translationResult += data.chunk
          replyTokens = this.estimateTokens(translationResult)
          
          const progress = Math.min((replyTokens / task.predictedTokens) * 100, 100)

          // å‘å°„è¿›åº¦äº‹ä»¶
          this.llmTranslateService.emit('task:progress', {
            batchId,
            taskId,
            replyTokens,
            progress,
            chunk: data.chunk
          })

          // æ›´æ–°æ•°æ®åº“è¿›åº¦
          projectDb.run(
            `UPDATE Llmtranslate_tasks 
             SET reply_tokens = ?, progress = ?, updated_at = CURRENT_TIMESTAMP 
             WHERE id = ?`,
            [replyTokens, progress, taskId]
          )
        }
      }

      this.llmChatService.on('message:chunk', chunkHandler)

      // ç­‰å¾…å“åº”å®Œæˆ
      await new Promise<void>((resolve, reject) => {
        const completeHandler = (data: { messageId: string; conversationId: string }) => {
          if (data.conversationId === conversationId && data.messageId === messageId) {
            this.llmChatService.off('message:chunk', chunkHandler)
            this.llmChatService.off('message:complete', completeHandler)
            this.llmChatService.off('message:error', errorHandler)
            resolve()
          }
        }

        const errorHandler = (data: { messageId: string; conversationId: string; error: string }) => {
          if (data.conversationId === conversationId && data.messageId === messageId) {
            this.llmChatService.off('message:chunk', chunkHandler)
            this.llmChatService.off('message:complete', completeHandler)
            this.llmChatService.off('message:error', errorHandler)
            reject(new Error(data.error))
          }
        }

        this.llmChatService.on('message:complete', completeHandler)
        this.llmChatService.on('message:error', errorHandler)
      })

      // 4. ä»»åŠ¡å®Œæˆ
      const durationMs = Date.now() - startTime
      const cost = this.calculateCost(task.inputTokens, replyTokens, config.modelId)

      await projectDb.run(
        `UPDATE Llmtranslate_tasks 
         SET status = 'completed', 
             translation = ?,
             reply_tokens = ?,
             progress = 100,
             reply_time = CURRENT_TIMESTAMP,
             duration_ms = ?,
             cost = ?,
             updated_at = CURRENT_TIMESTAMP
         WHERE id = ?`,
        [translationResult, replyTokens, durationMs, cost, taskId]
      )

      // 5. å‘å°„å®Œæˆäº‹ä»¶
      this.llmTranslateService.emit('task:complete', {
        batchId,
        taskId,
        translation: translationResult,
        totalTokens: replyTokens,
        durationMs,
        cost
      })

      // 6. æ¸…ç†ä¸´æ—¶å¯¹è¯
      await this.llmChatService.deleteConversation(conversationId)

    } catch (error) {
      // é”™è¯¯å¤„ç†
      const errorMessage = error instanceof Error ? error.message : String(error)
      let errorType: ErrorType = 'unknown'

      if (errorMessage.includes('429') || errorMessage.includes('rate limit')) {
        errorType = 'rate_limit'
        await projectDb.run(
          `UPDATE Llmtranslate_tasks 
           SET status = 'throttled', error_type = ?, error_message = ?, updated_at = CURRENT_TIMESTAMP 
           WHERE id = ?`,
          [errorType, errorMessage, taskId]
        )
      } else if (errorMessage.includes('timeout')) {
        errorType = 'timeout'
        await projectDb.run(
          `UPDATE Llmtranslate_tasks 
           SET status = 'error', error_type = ?, error_message = ?, updated_at = CURRENT_TIMESTAMP 
           WHERE id = ?`,
          [errorType, errorMessage, taskId]
        )
      } else {
        await projectDb.run(
          `UPDATE Llmtranslate_tasks 
           SET status = 'error', error_type = 'unknown', error_message = ?, updated_at = CURRENT_TIMESTAMP 
           WHERE id = ?`,
          [errorMessage, taskId]
        )
      }

      // å‘å°„é”™è¯¯äº‹ä»¶
      this.llmTranslateService.emit('task:error', {
        batchId,
        taskId,
        errorType,
        errorMessage
      })
    }
  }

  /**
   * æš‚åœæ‰¹æ¬¡
   */
  pauseBatch(batchId: string): void {
    this.pausedBatches.add(batchId)
    console.log(`â¸ï¸ [TranslationExecutor] æ‰¹æ¬¡ ${batchId} å·²æš‚åœ`)
  }

  /**
   * æ¢å¤æ‰¹æ¬¡
   */
  resumeBatch(batchId: string): void {
    this.pausedBatches.delete(batchId)
    console.log(`â–¶ï¸ [TranslationExecutor] æ‰¹æ¬¡ ${batchId} å·²æ¢å¤`)
    
    // TODO: é‡æ–°å¯åŠ¨å·¥ä½œçº¿ç¨‹
  }

  /**
   * ä¼°ç®— Token æ•°
   */
  private estimateTokens(text: string): number {
    return Math.ceil(text.length / 4)
  }

  /**
   * è®¡ç®—æˆæœ¬
   */
  private calculateCost(inputTokens: number, outputTokens: number, modelId: string): number {
    // ç¤ºä¾‹ä»·æ ¼ï¼ˆéœ€è¦æ ¹æ®å®é™…æ¨¡å‹è°ƒæ•´ï¼‰
    const INPUT_PRICE_PER_1K = 0.03  // $0.03 per 1K tokens
    const OUTPUT_PRICE_PER_1K = 0.06 // $0.06 per 1K tokens
    
    return (inputTokens / 1000) * INPUT_PRICE_PER_1K + (outputTokens / 1000) * OUTPUT_PRICE_PER_1K
  }

  /**
   * å»¶è¿Ÿå‡½æ•°
   */
  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms))
  }
}
```

---

## ğŸ”— **IPC é€šä¿¡å±‚**

### **æ–‡ä»¶ä½ç½®**
```
src-electron/ipc/main-renderer/llm-translate-handlers.ts
```

### **IPC Handlers å®ç°ï¼ˆçº¯Electron è¿›ç¨‹é—´é€šä¿¡ï¼‰**

```typescript
/**
 * LLM Translate IPC å¤„ç†å™¨
 * ä¸»è¿›ç¨‹ç›‘å¬æ¥è‡ªæ¸²æŸ“è¿›ç¨‹çš„ IPC æ¶ˆæ¯ï¼Œè°ƒç”¨ LlmTranslateService æ‰§è¡Œä¸šåŠ¡é€»è¾‘
 * é€šè¿‡äº‹ä»¶é©±åŠ¨æ¶æ„å‘æ‰€æœ‰æ¸²æŸ“çª—å£å¹¿æ’­è¿›åº¦åé¦ˆ
 * 
 * æ¶æ„è¯´æ˜ï¼š
 * - æ— åç«¯æœåŠ¡å™¨ï¼Œæ— ç½‘ç»œè¯·æ±‚
 * - æ‰€æœ‰æ•°æ®æ“ä½œåœ¨ä¸»è¿›ç¨‹æœ¬åœ°å®Œæˆ
 * - é€šè¿‡ IPC ä¸æ¸²æŸ“è¿›ç¨‹é€šä¿¡
 * - ä½¿ç”¨ EventEmitter å®ç°äº‹ä»¶é©±åŠ¨
 */

import { ipcMain, BrowserWindow, dialog } from 'electron'
import type { LlmTranslateService } from '../../services/llm-translate-service/llm-translate-service'
import type {
  TranslateConfig,
  ExportOptions,
  BatchCreateStartEvent,
  BatchCreatedEvent,
  BatchCreateErrorEvent,
  TaskSubmitStartEvent,
  TaskSubmittedEvent,
  TaskProgressEvent,
  TaskCompleteEvent,
  TaskErrorEvent,
  BatchPauseEvent,
  BatchResumeEvent,
  ExportStartEvent,
  ExportCompleteEvent,
  ExportErrorEvent
} from '../../services/llm-translate-service/types'

export function registerLlmTranslateHandlers(llmTranslateService: LlmTranslateService) {
  
  // ========== äº‹ä»¶ç›‘å¬å™¨ï¼ˆåªæ³¨å†Œä¸€æ¬¡ï¼‰ ==========
  
  llmTranslateService.on('batch:create-start', (data: BatchCreateStartEvent) => {
    BrowserWindow.getAllWindows().forEach(win => {
      win.webContents.send('llm-translate:batch-create-start', data)
    })
  })

  llmTranslateService.on('batch:created', (data: BatchCreatedEvent) => {
    BrowserWindow.getAllWindows().forEach(win => {
      win.webContents.send('llm-translate:batch-created', data)
    })
  })

  llmTranslateService.on('batch:create-error', (data: BatchCreateErrorEvent) => {
    BrowserWindow.getAllWindows().forEach(win => {
      win.webContents.send('llm-translate:batch-create-error', data)
    })
  })

  llmTranslateService.on('task:submit-start', (data: TaskSubmitStartEvent) => {
    BrowserWindow.getAllWindows().forEach(win => {
      win.webContents.send('llm-translate:task-submit-start', data)
    })
  })

  llmTranslateService.on('task:submitted', (data: TaskSubmittedEvent) => {
    BrowserWindow.getAllWindows().forEach(win => {
      win.webContents.send('llm-translate:task-submitted', data)
    })
  })

  llmTranslateService.on('task:progress', (data: TaskProgressEvent) => {
    BrowserWindow.getAllWindows().forEach(win => {
      win.webContents.send('llm-translate:task-progress', data)
    })
  })

  llmTranslateService.on('task:complete', (data: TaskCompleteEvent) => {
    BrowserWindow.getAllWindows().forEach(win => {
      win.webContents.send('llm-translate:task-complete', data)
    })
  })

  llmTranslateService.on('task:error', (data: TaskErrorEvent) => {
    BrowserWindow.getAllWindows().forEach(win => {
      win.webContents.send('llm-translate:task-error', data)
    })
  })

  llmTranslateService.on('batch:paused', (data: BatchPauseEvent) => {
    BrowserWindow.getAllWindows().forEach(win => {
      win.webContents.send('llm-translate:batch-paused', data)
    })
  })

  llmTranslateService.on('batch:resumed', (data: BatchResumeEvent) => {
    BrowserWindow.getAllWindows().forEach(win => {
      win.webContents.send('llm-translate:batch-resumed', data)
    })
  })

  llmTranslateService.on('export:start', (data: ExportStartEvent) => {
    BrowserWindow.getAllWindows().forEach(win => {
      win.webContents.send('llm-translate:export-start', data)
    })
  })

  llmTranslateService.on('export:complete', (data: ExportCompleteEvent) => {
    BrowserWindow.getAllWindows().forEach(win => {
      win.webContents.send('llm-translate:export-complete', data)
    })
  })

  llmTranslateService.on('export:error', (data: ExportErrorEvent) => {
    BrowserWindow.getAllWindows().forEach(win => {
      win.webContents.send('llm-translate:export-error', data)
    })
  })

  // ========== IPC Handlersï¼ˆçº¯è°ƒç”¨ï¼‰ ==========

  /**
   * åˆ›å»ºæ‰¹æ¬¡
   */
  ipcMain.handle('llm-translate:create-batch', async (_event, args: {
    config: TranslateConfig
    content: string
  }) => {
    try {
      const batchId = await llmTranslateService.createBatch(args.config, args.content)
      return { success: true, batchId }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error)
      return { success: false, error: errorMessage }
    }
  })

  /**
   * è·å–æ‰¹æ¬¡åˆ—è¡¨
   */
  ipcMain.handle('llm-translate:get-batches', async () => {
    try {
      const result = await llmTranslateService.getBatches()
      return { success: true, data: result }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error)
      return { success: false, error: errorMessage }
    }
  })

  /**
   * è·å–æ‰¹æ¬¡çš„ä»»åŠ¡åˆ—è¡¨
   */
  ipcMain.handle('llm-translate:get-tasks', async (_event, args: { batchId: string }) => {
    try {
      const result = await llmTranslateService.getTasks(args.batchId)
      return { success: true, data: result }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error)
      return { success: false, error: errorMessage }
    }
  })

  /**
   * è·å–å•ä¸ªä»»åŠ¡
   */
  ipcMain.handle('llm-translate:get-task', async (_event, args: { taskId: string }) => {
    try {
      const task = await llmTranslateService.getTask(args.taskId)
      return { success: true, data: task }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error)
      return { success: false, error: errorMessage }
    }
  })

  /**
   * æäº¤ä»»åŠ¡
   */
  ipcMain.handle('llm-translate:submit-tasks', async (_event, args: {
    batchId: string
    taskIds: string[]
  }) => {
    try {
      const submissionId = await llmTranslateService.submitTasks(args.batchId, args.taskIds)
      return { success: true, submissionId }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error)
      return { success: false, error: errorMessage }
    }
  })

  /**
   * é‡è¯•å¤±è´¥ä»»åŠ¡
   */
  ipcMain.handle('llm-translate:retry-failed-tasks', async (_event, args: { batchId: string }) => {
    try {
      const submissionId = await llmTranslateService.retryFailedTasks(args.batchId)
      return { success: true, submissionId }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error)
      return { success: false, error: errorMessage }
    }
  })

  /**
   * æš‚åœæ‰¹æ¬¡
   */
  ipcMain.handle('llm-translate:pause-batch', async (_event, args: { batchId: string }) => {
    try {
      await llmTranslateService.pauseBatch(args.batchId)
      return { success: true }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error)
      return { success: false, error: errorMessage }
    }
  })

  /**
   * æ¢å¤æ‰¹æ¬¡
   */
  ipcMain.handle('llm-translate:resume-batch', async (_event, args: { batchId: string }) => {
    try {
      await llmTranslateService.resumeBatch(args.batchId)
      return { success: true }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error)
      return { success: false, error: errorMessage }
    }
  })

  /**
   * é€‰æ‹©æ–‡ä»¶è·¯å¾„ï¼ˆæ–‡ä»¶ä¸Šä¼ ï¼‰
   */
  ipcMain.handle('llm-translate:select-file', async (event) => {
    try {
      const win = BrowserWindow.fromWebContents(event.sender)
      if (!win) throw new Error('Window not found')

      const result = await dialog.showOpenDialog(win, {
        title: 'é€‰æ‹©å¾…ç¿»è¯‘æ–‡ä»¶',
        properties: ['openFile'],
        filters: [
          { name: 'æ–‡æœ¬æ–‡ä»¶', extensions: ['txt', 'md'] },
          { name: 'æ‰€æœ‰æ–‡ä»¶', extensions: ['*'] }
        ]
      })

      if (result.canceled || result.filePaths.length === 0) {
        return { success: false, canceled: true }
      }

      const filePath = result.filePaths[0]
      
      // è¯»å–æ–‡ä»¶å†…å®¹
      const fs = await import('fs/promises')
      const content = await fs.readFile(filePath, 'utf-8')
      const stats = await fs.stat(filePath)

      return {
        success: true,
        data: {
          filePath,
          fileName: filePath.split(/[/\\]/).pop() || '',
          fileSize: stats.size,
          content
        }
      }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error)
      return { success: false, error: errorMessage }
    }
  })

  /**
   * é€‰æ‹©è¾“å‡ºç›®å½•ï¼ˆå¯¼å‡ºï¼‰
   */
  ipcMain.handle('llm-translate:select-output-dir', async (event) => {
    try {
      const win = BrowserWindow.fromWebContents(event.sender)
      if (!win) throw new Error('Window not found')

      const result = await dialog.showOpenDialog(win, {
        title: 'é€‰æ‹©è¾“å‡ºç›®å½•',
        properties: ['openDirectory']
      })

      if (result.canceled || result.filePaths.length === 0) {
        return { success: false, canceled: true }
      }

      return { success: true, data: { outputDir: result.filePaths[0] } }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error)
      return { success: false, error: errorMessage }
    }
  })

  /**
   * å¯¼å‡ºæ‰¹æ¬¡
   */
  ipcMain.handle('llm-translate:export-batch', async (_event, args: {
    batchId: string
    options: ExportOptions
  }) => {
    try {
      const exportId = await llmTranslateService.exportBatch(args.batchId, args.options)
      return { success: true, exportId }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error)
      return { success: false, error: errorMessage }
    }
  })

  console.log('âœ… [IPC] LLM Translate handlers registered')
}
```

---

## ğŸ’¾ **å‰ç«¯ Store é›†æˆ (å¼ºç±»å‹)**

### **æ›´æ–° LlmTranslate.store.ts**

```typescript
/**
 * LlmTranslate Store - IPC é€šä¿¡ç‰ˆæœ¬ï¼ˆçº¯Electronæœ¬åœ°åº”ç”¨ï¼‰
 * å¼ºç±»å‹ï¼Œäº‹ä»¶é©±åŠ¨
 * é€šè¿‡ IPC ä¸ä¸»è¿›ç¨‹çš„ LlmTranslateService é€šä¿¡
 */

import { defineStore } from 'pinia'
import { ref, computed } from 'vue'
import { mockBatchList, mockTaskList } from './mock'
import type { 
  Batch, 
  Task, 
  TranslateConfig, 
  TaskFilter,
  BatchCreateStartEvent,
  BatchCreatedEvent,
  TaskProgressEvent,
  TaskCompleteEvent,
  TaskErrorEvent
} from '../types'

// â­ æ— åç«¯æœåŠ¡å™¨ï¼Œæ‰€æœ‰æ“ä½œé€šè¿‡ IPC åœ¨æœ¬åœ°è¿›è¡Œ
// æ¸²æŸ“è¿›ç¨‹ â†â†’ IPC Bridge â†â†’ ä¸»è¿›ç¨‹ (LlmTranslateService)

export const useLlmTranslateStore = defineStore('llmTranslate', () => {
  // â­ å•ä¸€å¼€å…³ï¼šæ”¹è¿™é‡Œåˆ‡æ¢ Mock â†” Electron æœ¬åœ°æœåŠ¡
  const useMock = ref(import.meta.env.MODE === 'development')

  // ==================== çŠ¶æ€å®šä¹‰ ====================
  
  const config = ref<TranslateConfig>({
    inputSource: 'file',
    content: '',
    filePath: '',
    systemPrompt: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ï¼Œè¯·å°†ä»¥ä¸‹å†…å®¹ç¿»è¯‘æˆè‹±æ–‡ã€‚',
    chunkStrategy: 'line',
    chunkSize: 50,
    concurrency: 3,
    replyMode: 'predicted',
    predictedTokens: 2000,
    modelId: 'gpt-4',
    outputDir: 'D:\\output\\translate\\'
  })

  const batchList = ref<Batch[]>([])
  const currentBatch = ref<Batch | null>(null)
  const taskList = ref<Task[]>([])
  const selectedTasks = ref<string[]>([])
  const taskFilters = ref<TaskFilter>({
    status: ['waiting', 'throttled', 'error', 'unsent'],
    searchText: ''
  })
  const threadDrawer = ref({
    isOpen: false,
    currentTaskId: null as string | null
  })
  const loading = ref(false)
  const error = ref<string | null>(null)

  // ==================== äº‹ä»¶ç›‘å¬å™¨è®¾ç½® ==========

  function setupListeners(): void {
    if (useMock.value) return  // Mock æ¨¡å¼ä¸éœ€è¦ç›‘å¬

    // æ‰¹æ¬¡åˆ›å»ºäº‹ä»¶
    window.nimbria.llmTranslate.onBatchCreateStart((data: BatchCreateStartEvent) => {
      console.log('ğŸ“¦ [Store] æ‰¹æ¬¡åˆ›å»ºå¼€å§‹:', data.batchId)
    })

    window.nimbria.llmTranslate.onBatchCreated((data: BatchCreatedEvent) => {
      console.log('âœ… [Store] æ‰¹æ¬¡åˆ›å»ºå®Œæˆ:', data.batchId)
      
      // æ›´æ–°æ‰¹æ¬¡åˆ—è¡¨
      batchList.value.unshift(data.batch)
      currentBatch.value = data.batch
      taskList.value = data.tasks
    })

    window.nimbria.llmTranslate.onBatchCreateError((data: BatchCreateErrorEvent) => {
      console.error('âŒ [Store] æ‰¹æ¬¡åˆ›å»ºå¤±è´¥:', data.error)
      error.value = data.error
    })

    // ä»»åŠ¡è¿›åº¦äº‹ä»¶
    window.nimbria.llmTranslate.onTaskProgress((data: TaskProgressEvent) => {
      const task = taskList.value.find((t: Task) => t.id === data.taskId)
      if (task) {
        task.replyTokens = data.replyTokens
        task.progress = data.progress
        task.translation = (task.translation || '') + data.chunk
      }
    })

    // ä»»åŠ¡å®Œæˆäº‹ä»¶
    window.nimbria.llmTranslate.onTaskComplete((data: TaskCompleteEvent) => {
      const task = taskList.value.find((t: Task) => t.id === data.taskId)
      if (task) {
        task.status = 'completed'
        task.translation = data.translation
        task.progress = 100
        task.replyTokens = data.totalTokens
      }
      
      // æ›´æ–°æ‰¹æ¬¡ç»Ÿè®¡
      if (currentBatch.value && currentBatch.value.id === data.batchId) {
        currentBatch.value.completedTasks++
      }
    })

    // ä»»åŠ¡é”™è¯¯äº‹ä»¶
    window.nimbria.llmTranslate.onTaskError((data: TaskErrorEvent) => {
      const task = taskList.value.find((t: Task) => t.id === data.taskId)
      if (task) {
        if (data.errorType === 'rate_limit') {
          task.status = 'throttled'
        } else {
          task.status = 'error'
        }
        task.errorMessage = data.errorMessage
        task.errorType = data.errorType
      }
      
      // æ›´æ–°æ‰¹æ¬¡ç»Ÿè®¡
      if (currentBatch.value && currentBatch.value.id === data.batchId) {
        if (data.errorType === 'rate_limit') {
          currentBatch.value.throttledTasks++
        } else {
          currentBatch.value.failedTasks++
        }
      }
    })
  }

  // ==================== æ•°æ®è·å–æ–¹æ³• ====================

  async function fetchBatchList(): Promise<void> {
    loading.value = true
    error.value = null

    try {
      if (useMock.value) {
        batchList.value = mockBatchList
      } else {
        // é€šè¿‡ IPC è°ƒç”¨ä¸»è¿›ç¨‹çš„ getBatches()
        const result = await window.nimbria.llmTranslate.getBatches()
        if (result.success && result.data) {
          batchList.value = result.data.batches
        } else {
          throw new Error(result.error || 'è·å–æ‰¹æ¬¡åˆ—è¡¨å¤±è´¥')
        }
      }
    } catch (err) {
      error.value = err instanceof Error ? err.message : 'è·å–æ‰¹æ¬¡åˆ—è¡¨å¤±è´¥'
      console.error('Failed to fetch batch list:', err)
    } finally {
      loading.value = false
    }
  }

  async function fetchTaskList(batchId: string): Promise<void> {
    loading.value = true
    error.value = null

    try {
      if (useMock.value) {
        taskList.value = mockTaskList.filter((t: Task) => t.batchId === batchId)
      } else {
        // é€šè¿‡ IPC è°ƒç”¨ä¸»è¿›ç¨‹çš„ getTasks()
        const result = await window.nimbria.llmTranslate.getTasks({ batchId })
        if (result.success && result.data) {
          taskList.value = result.data.tasks
        } else {
          throw new Error(result.error || 'è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥')
        }
      }
    } catch (err) {
      error.value = err instanceof Error ? err.message : 'è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥'
      console.error('Failed to fetch task list:', err)
    } finally {
      loading.value = false
    }
  }

  async function createBatch(configData: TranslateConfig): Promise<Batch> {
    loading.value = true
    error.value = null

    try {
      if (useMock.value) {
        // Mock æ¨¡å¼
        const newBatch: Batch = {
          id: `#${Date.now().toString().slice(-8)}`,
          status: 'running',
          totalTasks: 100,
          completedTasks: 0,
          failedTasks: 0,
          throttledTasks: 0,
          waitingTasks: 0,
          unsentTasks: 100,
          terminatedTasks: 0,
          totalCost: 0,
          totalInputTokens: 0,
          totalOutputTokens: 0,
          avgTimePerTask: 0,
          createdAt: new Date().toISOString(),
          startedAt: null,
          completedAt: null,
          updatedAt: new Date().toISOString()
        }
        currentBatch.value = newBatch
        batchList.value.unshift(newBatch)
        return newBatch
      } else {
        // é€šè¿‡ IPC è°ƒç”¨ä¸»è¿›ç¨‹åˆ›å»ºæ‰¹æ¬¡
        const result = await window.nimbria.llmTranslate.createBatch({
          config: configData,
          content: configData.content
        })
        
        if (!result.success || !result.batchId) {
          throw new Error(result.error || 'åˆ›å»ºæ‰¹æ¬¡å¤±è´¥')
        }

        // ç­‰å¾…æ‰¹æ¬¡åˆ›å»ºå®Œæˆäº‹ä»¶ï¼ˆé€šè¿‡ Promise + äº‹ä»¶ç›‘å¬ï¼‰
        return await new Promise<Batch>((resolve, reject) => {
          const timeout = setTimeout(() => reject(new Error('åˆ›å»ºè¶…æ—¶')), 10000)
          
          const handler = (data: BatchCreatedEvent) => {
            if (data.batchId === result.batchId) {
              clearTimeout(timeout)
              resolve(data.batch)
            }
          }
          
          window.nimbria.llmTranslate.onBatchCreated(handler)
        })
      }
    } catch (err) {
      error.value = err instanceof Error ? err.message : 'åˆ›å»ºæ‰¹æ¬¡å¤±è´¥'
      throw err
    } finally {
      loading.value = false
    }
  }

  // ... å…¶ä»–æ–¹æ³•ä¿æŒä¸å˜

  return {
    config,
    batchList,
    currentBatch,
    taskList,
    selectedTasks,
    taskFilters,
    threadDrawer,
    loading,
    error,
    setupListeners,
    fetchBatchList,
    fetchTaskList,
    createBatch
    // ... å…¶ä»–æ–¹æ³•
  }
})
```

---

## ğŸ”— **Preload API å®šä¹‰ (å¼ºç±»å‹)**

### **æ–‡ä»¶ä½ç½®**
```
src-electron/core/project-preload.ts
```

### **IPC é€šä¿¡ API æš´éœ²ï¼ˆçº¯Electronï¼‰**

```typescript
/**
 * LLM Translate IPC API - ä¸»è¿›ç¨‹é€šä¿¡æ¥å£ï¼ˆå¼ºç±»å‹ï¼‰
 * 
 * æ¶æ„æµç¨‹ï¼š
 * æ¸²æŸ“è¿›ç¨‹ â†’ ipcRenderer â†’ IPC Bridge â†’ ä¸»è¿›ç¨‹ LlmTranslateService â†’ æ•°æ®åº“/LLM
 * 
 * âš ï¸ æ— åç«¯æœåŠ¡å™¨ï¼Œæ‰€æœ‰æ•°æ®æ“ä½œéƒ½åœ¨ä¸»è¿›ç¨‹æœ¬åœ°å®Œæˆ
 */

import type {
  TranslateConfig,
  ExportOptions,
  Batch,
  Task,
  BatchListResponse,
  TaskListResponse,
  ApiResponse
} from '../services/llm-translate-service/types'

// åœ¨ contextBridge.exposeInMainWorld ä¸­æ·»åŠ 
llmTranslate: {
  // ===== æ•°æ®æŸ¥è¯¢ï¼ˆåŒæ­¥IPCè°ƒç”¨ï¼‰ =====
  getBatches: (): Promise<ApiResponse<BatchListResponse>> => 
    ipcRenderer.invoke('llm-translate:get-batches'),
  
  getTasks: (args: { batchId: string }): Promise<ApiResponse<TaskListResponse>> =>
    ipcRenderer.invoke('llm-translate:get-tasks', args),
  
  getTask: (args: { taskId: string }): Promise<ApiResponse<Task | null>> =>
    ipcRenderer.invoke('llm-translate:get-task', args),
  
  // ===== æ‰¹æ¬¡æ“ä½œï¼ˆå¼‚æ­¥IPCè°ƒç”¨ + äº‹ä»¶åé¦ˆï¼‰ =====
  createBatch: (args: { config: TranslateConfig; content: string }): Promise<ApiResponse<{ batchId: string }>> =>
    ipcRenderer.invoke('llm-translate:create-batch', args),
  
  submitTasks: (args: { batchId: string; taskIds: string[] }): Promise<ApiResponse<{ submissionId: string }>> =>
    ipcRenderer.invoke('llm-translate:submit-tasks', args),
  
  retryFailedTasks: (args: { batchId: string }): Promise<ApiResponse<{ submissionId: string }>> =>
    ipcRenderer.invoke('llm-translate:retry-failed-tasks', args),
  
  pauseBatch: (args: { batchId: string }): Promise<ApiResponse<void>> =>
    ipcRenderer.invoke('llm-translate:pause-batch', args),
  
  resumeBatch: (args: { batchId: string }): Promise<ApiResponse<void>> =>
    ipcRenderer.invoke('llm-translate:resume-batch', args),
  
  // ===== æœ¬åœ°æ–‡ä»¶æ“ä½œï¼ˆElectron Dialogï¼‰ =====
  selectFile: (): Promise<ApiResponse<{ filePath: string; fileName: string; fileSize: number; content: string }>> =>
    ipcRenderer.invoke('llm-translate:select-file'),
  
  selectOutputDir: (): Promise<ApiResponse<{ outputDir: string }>> =>
    ipcRenderer.invoke('llm-translate:select-output-dir'),
  
  exportBatch: (args: { batchId: string; options: ExportOptions }): Promise<ApiResponse<{ exportId: string }>> =>
    ipcRenderer.invoke('llm-translate:export-batch', args),
  
  // ===== äº‹ä»¶ç›‘å¬ï¼ˆIPC äº‹ä»¶æµï¼‰ =====
  // è¿™äº›äº‹ä»¶ç”±ä¸»è¿›ç¨‹å‘å°„ï¼Œæ¸²æŸ“è¿›ç¨‹ç›‘å¬ä»¥è·å–å®æ—¶åé¦ˆ
  
  onBatchCreateStart: (callback: (data: BatchCreateStartEvent) => void) => {
    ipcRenderer.on('llm-translate:batch-create-start', (_event, data) => callback(data))
  },
  
  onBatchCreated: (callback: (data: BatchCreatedEvent) => void) => {
    ipcRenderer.on('llm-translate:batch-created', (_event, data) => callback(data))
  },
  
  onBatchCreateError: (callback: (data: BatchCreateErrorEvent) => void) => {
    ipcRenderer.on('llm-translate:batch-create-error', (_event, data) => callback(data))
  },
  
  onTaskProgress: (callback: (data: TaskProgressEvent) => void) => {
    ipcRenderer.on('llm-translate:task-progress', (_event, data) => callback(data))
  },
  
  onTaskComplete: (callback: (data: TaskCompleteEvent) => void) => {
    ipcRenderer.on('llm-translate:task-complete', (_event, data) => callback(data))
  },
  
  onTaskError: (callback: (data: TaskErrorEvent) => void) => {
    ipcRenderer.on('llm-translate:task-error', (_event, data) => callback(data))
  }
  
  // ... å…¶ä»–äº‹ä»¶ç›‘å¬å™¨
}
```

---

## ğŸ“‹ **å¾ªåºæ¸è¿›å®ç° TODO (5 é˜¶æ®µ)**

```markdown
### Phase 0: å‡†å¤‡å·¥ä½œ âœ…
- [x] åˆ›å»º `src-electron/services/llm-translate-service/` ç›®å½•
- [x] åˆ›å»º `types.ts` - å®šä¹‰æ‰€æœ‰å¼ºç±»å‹æ¥å£
- [x] åˆ›å»º Schema v1.2.0 - å®šä¹‰æ•°æ®åº“è¡¨ç»“æ„

### Phase 1: æ•°æ®æŸ¥è¯¢ï¼ˆæœ¬åœ°IPCè¯»å–ï¼‰
- [ ] å®ç° `LlmTranslateService.getBatches()` - ä»SQLiteæŸ¥è¯¢æ‰¹æ¬¡åˆ—è¡¨
- [ ] å®ç° `LlmTranslateService.getTasks(batchId)` - ä»SQLiteæŸ¥è¯¢ä»»åŠ¡åˆ—è¡¨
- [ ] å®ç° `LlmTranslateService.getTask(taskId)` - ä»SQLiteæŸ¥è¯¢å•ä¸ªä»»åŠ¡
- [ ] æ³¨å†Œ IPC Handlers: `llm-translate:get-batches`, `llm-translate:get-tasks`, `llm-translate:get-task`
- [ ] æ›´æ–° `project-preload.ts` - æš´éœ²IPCæ–¹æ³•
- [ ] **æµ‹è¯•**: å‰ç«¯é€šè¿‡IPCè°ƒç”¨ï¼ŒéªŒè¯ä»æ•°æ®åº“è¯»å–æ•°æ®

### Phase 2: æ‰¹æ¬¡åˆ›å»ºï¼ˆäº‹ä»¶é©±åŠ¨å¼‚æ­¥ï¼‰
- [ ] å®ç° `LlmTranslateService.createBatch()` - åˆ›å»ºæ‰¹æ¬¡å’Œå†…å®¹åˆ†ç‰‡
- [ ] å®ç° `chunkContent()` - æŒ‰è¡Œ/æŒ‰Tokenåˆ†ç‰‡é€»è¾‘
- [ ] å®ç° `handleTerminatedTasks()` - ç¨‹åºä¸­æ–­æ¢å¤ï¼ˆå°†waitingæ ‡è®°ä¸ºterminatedï¼‰
- [ ] æ³¨å†Œäº‹ä»¶ç›‘å¬å™¨: `batch:create-start`, `batch:created`, `batch:create-error`
- [ ] æ³¨å†Œ IPC Handler: `llm-translate:create-batch`ï¼ˆç«‹å³è¿”å›batchIdï¼‰
- [ ] å‰ç«¯ Store æ·»åŠ äº‹ä»¶ç›‘å¬: `setupListeners()`
- [ ] **æµ‹è¯•**: è°ƒç”¨createBatch â†’ ç›‘å¬äº‹ä»¶åé¦ˆ â†’ éªŒè¯æ•°æ®åº“ä¸­çš„åˆ†ç‰‡

### Phase 3: ä»»åŠ¡æ‰§è¡Œï¼ˆæµå¼ç¿»è¯‘ï¼‰
- [ ] å®ç° `TranslationExecutor.executeTasks()` - ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†
- [ ] å®ç° `TranslationExecutor.worker()` - å¹¶å‘å·¥ä½œçº¿ç¨‹
- [ ] å®ç° `TranslationExecutor.executeTask()` - å•ä¸ªä»»åŠ¡æ‰§è¡Œ
- [ ] é›†æˆ `LlmChatService` - è°ƒç”¨æœ¬åœ°LLMæœåŠ¡
- [ ] å®ç°æµå¼è¿›åº¦æ›´æ–° - ç›‘å¬ `message:chunk` äº‹ä»¶å¹¶å¹¿æ’­è¿›åº¦
- [ ] æ³¨å†Œä»»åŠ¡äº‹ä»¶: `task:submitted`, `task:progress`, `task:complete`, `task:error`
- [ ] **æµ‹è¯•**: æäº¤ä»»åŠ¡ â†’ è§‚å¯Ÿæµå¼è¿›åº¦ â†’ éªŒè¯ç¿»è¯‘ç»“æœä¿å­˜

### Phase 4: æ§åˆ¶ä¸å¯¼å‡º
- [ ] å®ç° `pauseBatch()` / `resumeBatch()` - æš‚åœ/æ¢å¤æ‰¹æ¬¡
- [ ] å®ç° `retryFailedTasks()` - é‡è¯•å¤±è´¥çš„ä»»åŠ¡
- [ ] å®ç° `ExportService.export()` - å¯¼å‡ºæœåŠ¡
- [ ] å®ç°æœ¬åœ°æ–‡ä»¶é€‰æ‹©: `llm-translate:select-file`, `llm-translate:select-output-dir`
- [ ] å®ç°å¯¼å‡ºæ ¼å¼ç”Ÿæˆ: TXT / CSV / JSON
- [ ] **æµ‹è¯•**: æš‚åœ/æ¢å¤æ‰¹æ¬¡ â†’ é‡è¯•å¤±è´¥ä»»åŠ¡ â†’ éªŒè¯æ–‡ä»¶å¯¼å‡º

### Phase 5: ç»Ÿè®¡ä¸ä¼˜åŒ–
- [ ] å®ç° `updateBatchStats()` - å®æ—¶æ›´æ–°æ‰¹æ¬¡ç»Ÿè®¡
- [ ] å®ç° `Llmtranslate_stats` è¡¨çš„ç»Ÿè®¡è®¡ç®—
- [ ] å®ç°é”™è¯¯åˆ†ç±»ç»Ÿè®¡: network/timeout/rate_limit/terminated
- [ ] ä¼˜åŒ–å¹¶å‘æ§åˆ¶: é™æµæ—¶è‡ªåŠ¨é™ä½å¹¶å‘
- [ ] ä¼˜åŒ–é‡è¯•æœºåˆ¶: æŒ‡æ•°é€€é¿ç®—æ³•
- [ ] **æµ‹è¯•**: æŸ¥çœ‹ç»Ÿè®¡åˆ†æ â†’ éªŒè¯æ€§èƒ½æŒ‡æ ‡å‡†ç¡®
```

---

## ğŸ¯ **å…³é”®å®ç°è¦ç‚¹**

### 1. **ç¨‹åºä¸­æ–­å¤„ç†ï¼ˆElectron graceful shutdownï¼‰**
```typescript
// åœ¨ LlmTranslateService.initialize() ä¸­
await this.handleTerminatedTasks()

private async handleTerminatedTasks(): Promise<void> {
  const terminatedTasks = await projectDb.query<Task>(
    `UPDATE Llmtranslate_tasks 
     SET status = 'terminated', 
         error_type = 'terminated',
         error_message = 'ç¨‹åºå¼‚å¸¸ç»ˆæ­¢ï¼Œä»»åŠ¡æœªå®Œæˆ'
     WHERE status = 'waiting'
     RETURNING *`
  )
  // æ›´æ–°æ‰¹æ¬¡ç»Ÿè®¡...
}
```

### 2. **æœ¬åœ°æ–‡ä»¶æ“ä½œï¼ˆElectron Dialog APIï¼‰**
```typescript
// Electron Dialog é€‰æ‹©æ–‡ä»¶ï¼ˆæœ¬åœ°ï¼‰
const result = await dialog.showOpenDialog(win, {
  title: 'é€‰æ‹©å¾…ç¿»è¯‘æ–‡ä»¶',
  properties: ['openFile'],
  filters: [{ name: 'æ–‡æœ¬æ–‡ä»¶', extensions: ['txt', 'md'] }]
})

// æœ¬åœ°è¯»å–æ–‡ä»¶å†…å®¹
const fs = await import('fs/promises')
const content = await fs.readFile(filePath, 'utf-8')
```

### 3. **å¼ºç±»å‹çº¦æŸ**
- âœ… æ‰€æœ‰å‡½æ•°å‚æ•°å’Œè¿”å›å€¼éƒ½æœ‰æ˜ç¡®ç±»å‹
- âœ… äº‹ä»¶æ•°æ®ä½¿ç”¨ `interface` å®šä¹‰
- âœ… æ•°æ®åº“æŸ¥è¯¢ç»“æœä½¿ç”¨æ³›å‹ `query<T>()`
- âœ… ç¦æ­¢ `any`ï¼Œä½¿ç”¨ `unknown` + ç±»å‹å®ˆå«
- âœ… IPC æ¶ˆæ¯ç±»å‹å®Œå…¨åŒ¹é…

### 4. **äº‹ä»¶é©±åŠ¨æµç¨‹ï¼ˆElectron IPC + EventEmitterï¼‰**
```
æ¸²æŸ“è¿›ç¨‹ (createBatch)
  â†’ IPC invoke â†’ ä¸»è¿›ç¨‹
  â†’ createBatch() ç«‹å³è¿”å› batchId
  â†’ emit('batch:create-start')
  â†’ å¼‚æ­¥å¤„ç†åˆ†ç‰‡
  â†’ emit('batch:created')
  â†’ IPC send å¹¿æ’­ç»™æ‰€æœ‰æ¸²æŸ“çª—å£
  â†’ æ¸²æŸ“è¿›ç¨‹ç›‘å¬äº‹ä»¶æ›´æ–°UI
```

### 5. **æœ¬åœ°LLMè°ƒç”¨ï¼ˆLlmChatServiceï¼‰**
```
ç¿»è¯‘æ‰§è¡Œå™¨ â†’ LlmChatService.sendMessage()
  â†’ æœ¬åœ° LLM æ¨ç†ï¼ˆæ— ç½‘ç»œè°ƒç”¨ï¼‰
  â†’ æµå¼å“åº”
  â†’ ç›‘å¬ message:chunk äº‹ä»¶
  â†’ å¹¿æ’­ task:progress äº‹ä»¶
```

### 6. **æœ¬åœ°æ•°æ®æŒä¹…åŒ–ï¼ˆSQLiteï¼‰**
- æ‰€æœ‰æ‰¹æ¬¡å’Œä»»åŠ¡æ•°æ®å­˜å‚¨åœ¨æœ¬åœ° SQLite æ•°æ®åº“
- æ”¯æŒç¨‹åºé‡å¯åæ¢å¤æœªå®Œæˆçš„ä»»åŠ¡
- æ— äº‘åŒæ­¥ï¼Œçº¯æœ¬åœ°å­˜å‚¨
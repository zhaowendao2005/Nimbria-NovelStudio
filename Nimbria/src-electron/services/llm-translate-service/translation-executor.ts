/**
 * ç¿»è¯‘æ‰§è¡Œå™¨ - Electron ä¸»è¿›ç¨‹ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†å™¨
 * 
 * èŒè´£ï¼š
 * - ç®¡ç†ä»»åŠ¡é˜Ÿåˆ—ï¼ˆFIFOï¼‰
 * - å¹¶å‘æ§åˆ¶ï¼ˆé™åˆ¶åŒæ—¶æ‰§è¡Œçš„ä»»åŠ¡æ•°ï¼‰
 * - é›†æˆ LlmTranslationClient è¿›è¡Œç¿»è¯‘
 * - é›†æˆ TaskStateManager ç®¡ç†çŠ¶æ€
 * - ç›‘å¬æµå¼å“åº”å¹¶å¹¿æ’­è¿›åº¦äº‹ä»¶
 * - é”™è¯¯æ•è·å’Œé‡è¯•é€»è¾‘
 * 
 * âš ï¸ æ‰€æœ‰æ“ä½œéƒ½åœ¨ä¸»è¿›ç¨‹æœ¬åœ°å®Œæˆï¼Œæ— å¤–éƒ¨ç½‘ç»œè°ƒç”¨
 */

import type { LlmTranslateService } from './llm-translate-service'
import { LlmTranslationClient } from './llm-translation-client'
import type { TaskStateManager } from './task-state-manager'
import type { 
  TranslationClientConfig,
  TranslationRequest,
  TranslationResult,
  ErrorType
} from '../../types/LlmTranslate/backend'
import type { TranslateConfig } from '../../types/LlmTranslate'

export class TranslationExecutor {
  private llmTranslateService: LlmTranslateService
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  private llmConfigManager: any
  private taskStateManager: TaskStateManager
  private taskQueues: Map<string, string[]> = new Map()  // batchId -> taskIds[]
  private pausedBatches: Set<string> = new Set()
  private activeTaskCount: Map<string, number> = new Map()  // batchId -> count
  private executingTasks: Map<string, LlmTranslationClient> = new Map()  // taskId -> client

  constructor(
    llmTranslateService: LlmTranslateService,
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    llmConfigManager: any,
    taskStateManager: TaskStateManager
  ) {
    this.llmTranslateService = llmTranslateService
    this.llmConfigManager = llmConfigManager
    this.taskStateManager = taskStateManager
  }

  /**
   * æ‰§è¡Œä»»åŠ¡é˜Ÿåˆ—
   * ä½¿ç”¨å¹¶å‘æ§åˆ¶ï¼Œé™åˆ¶åŒæ—¶æ‰§è¡Œçš„ä»»åŠ¡æ•°
   */
  async executeTasks(
    batchId: string,
    taskIds: string[],
    config: TranslateConfig,
    concurrency: number
  ): Promise<void> {
    this.taskQueues.set(batchId, [...taskIds])
    this.activeTaskCount.set(batchId, 0)

    // ç”Ÿæˆç³»ç»Ÿæç¤ºè¯æ‘˜è¦ï¼ˆå‰50ä¸ªå­—ç¬¦ï¼‰
    const systemPromptSummary = config.systemPrompt 
      ? (config.systemPrompt.length > 50 
          ? config.systemPrompt.substring(0, 50) + '...' 
          : config.systemPrompt)
      : '(æ— ç³»ç»Ÿæç¤ºè¯)'

    console.log(`ğŸ¬ [TranslationExecutor] å¼€å§‹æ‰§è¡Œæ‰¹æ¬¡ ${batchId}ï¼Œå…± ${taskIds.length} ä¸ªä»»åŠ¡ï¼Œå¹¶å‘: ${concurrency}`)
    console.log(`   ğŸ“ ç³»ç»Ÿæç¤ºè¯: ${systemPromptSummary}`)

    // å¯åŠ¨å¹¶å‘ worker
    const workers: Promise<void>[] = []
    for (let i = 0; i < Math.min(concurrency, taskIds.length); i++) {
      workers.push(this.worker(batchId, config))
    }

    await Promise.all(workers)

    console.log(`âœ… [TranslationExecutor] æ‰¹æ¬¡ ${batchId} æ‰§è¡Œå®Œæˆ`)

    // âŒ å·²ç§»é™¤ï¼šä¸å†åœ¨è¿™é‡Œæ¸…ç†æ‰¹æ¬¡çŠ¶æ€
    // æ‰¹æ¬¡çŠ¶æ€ç”± BatchScheduler åœ¨ scheduler:completed æ—¶ç®¡ç†
  }

  /**
   * Worker çº¿ç¨‹ï¼šä¸æ–­ä»é˜Ÿåˆ—å–ä»»åŠ¡å¹¶æ‰§è¡Œ
   */
  private async worker(batchId: string, config: TranslateConfig): Promise<void> {
    while (true) {
      // æ£€æŸ¥æ˜¯å¦æš‚åœ
      if (this.pausedBatches.has(batchId)) {
        console.log(`â¸ï¸ [TranslationExecutor] æ‰¹æ¬¡ ${batchId} å·²æš‚åœï¼Œå·¥ä½œçº¿ç¨‹é€€å‡º`)
        break
      }

      // ä»é˜Ÿåˆ—å–ä»»åŠ¡
      const queue = this.taskQueues.get(batchId)
      if (!queue || queue.length === 0) {
        break  // é˜Ÿåˆ—ç©ºäº†ï¼Œé€€å‡º
      }

      const taskId = queue.shift()
      if (!taskId) break

      // æ‰§è¡Œä»»åŠ¡
      await this.executeTask(batchId, taskId, config)

      // ç­‰å¾…é—´éš”ï¼ˆé˜²æ­¢é™æµï¼‰
      // æ³¨æ„ï¼šå½“ä½¿ç”¨BatchScheduleræ—¶ï¼Œå¹¶å‘æ§åˆ¶å·²åœ¨è°ƒåº¦å™¨å±‚å®ç°ï¼Œæ­¤å¤„delayå¯ä»¥å¾ˆå°
      // è¿™é‡Œä¿ç•™100msä½œä¸ºé˜²æŠ–ï¼Œé¿å…è¿‡å¿«çš„è¿ç»­è¯·æ±‚
      await this.delay(100)
    }
  }

  /**
   * æ‰§è¡Œå•ä¸ªä»»åŠ¡ï¼ˆæ–°ç‰ˆæœ¬ï¼šé›†æˆ LlmTranslationClient å’Œ TaskStateManagerï¼‰
   */
  private async executeTask(
    batchId: string,
    taskId: string,
    config: TranslateConfig
  ): Promise<void> {
    const projectDb = this.llmTranslateService.getProjectDatabase()
    if (!projectDb) return

    try {
      // 1. è·å–ä»»åŠ¡ä¿¡æ¯
      const { tasks } = await this.llmTranslateService.getTasks(batchId)
      const task = tasks.find(t => t.id === taskId)
      
      if (!task) {
        throw new Error(`Task ${taskId} not found`)
      }

      // 2. åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
      this.taskStateManager.initializeTask(taskId, batchId, config.predictedTokens)

      // 3. æ›´æ–°çŠ¶æ€ä¸º waiting
      await this.taskStateManager.updateState(taskId, 'waiting')

      // 4. ä¸‰å±‚è¶…æ—¶æ§åˆ¶é…ç½®
      /**
       * ä¸‰å±‚è¶…æ—¶æ¶æ„ï¼š
       * Layer 3: taskTotalTimeout - å…œåº•æœºåˆ¶ï¼ŒåŒ…æ‹¬æ’é˜Ÿã€æ‰§è¡Œã€é‡è¯•çš„å…¨éƒ¨æ—¶é—´
       * Layer 2a: httpTimeout - éæµå¼æ¨¡å¼çš„HTTPè¯·æ±‚æœ€é•¿ç­‰å¾…æ—¶é—´
       * Layer 2b: streamFirstTokenTimeout + streamIdleTimeout - æµå¼æ¨¡å¼çš„è¶…æ—¶æ§åˆ¶
       * 
       * ä¼˜å…ˆçº§: æœåŠ¡å™¨è¿”å› > æˆ‘ä»¬çš„è¶…æ—¶æ§åˆ¶
       */
      const taskTotalTimeout = config.taskTotalTimeout ?? 600000       // é»˜è®¤10åˆ†é’Ÿï¼ˆå…œåº•ï¼‰
      const httpTimeout = config.httpTimeout ?? 120000                  // é»˜è®¤2åˆ†é’Ÿï¼ˆéæµå¼ï¼‰
      const streamFirstTokenTimeout = config.streamFirstTokenTimeout ?? 60000  // é»˜è®¤1åˆ†é’Ÿ
      const streamIdleTimeout = config.streamIdleTimeout ?? 60000       // é»˜è®¤1åˆ†é’Ÿ
      const enableStreaming = config.enableStreaming ?? true

      // åˆ›å»ºç¿»è¯‘å®¢æˆ·ç«¯é…ç½®
      const clientConfig: TranslationClientConfig = {
        modelId: config.modelId,
        systemPrompt: config.systemPrompt,
        // ä½¿ç”¨ç”¨æˆ·é…ç½®çš„å‚æ•°ï¼ˆå¯é€‰ï¼‰ï¼Œä¸è®¾ç½®åˆ™ç”±å±‚å é…ç½®å†³å®š
        ...(config.temperature !== undefined && { temperature: config.temperature }),
        ...(config.maxTokens !== undefined && { maxTokens: config.maxTokens }),
        ...(config.topP !== undefined && { topP: config.topP }),
        ...(config.frequencyPenalty !== undefined && { frequencyPenalty: config.frequencyPenalty }),
        ...(config.presencePenalty !== undefined && { presencePenalty: config.presencePenalty }),
        // Layer 2a/2b è¶…æ—¶é…ç½®
        timeout: httpTimeout,
        maxRetries: config.maxRetries ?? 3,
        enableStreaming,
        streamFirstTokenTimeout,
        streamIdleTimeout
      }

      // ç”Ÿæˆç³»ç»Ÿæç¤ºè¯æ‘˜è¦ç”¨äºæ—¥å¿—
      const promptSummary = config.systemPrompt 
        ? (config.systemPrompt.length > 50 
            ? config.systemPrompt.substring(0, 50) + '...' 
            : config.systemPrompt)
        : '(æ— ç³»ç»Ÿæç¤ºè¯)'
      
      console.log(`ğŸš€ [TranslationExecutor] æ‰§è¡Œä»»åŠ¡ ${taskId}`)
      console.log(`   ğŸ“ ç³»ç»Ÿæç¤ºè¯: ${promptSummary}`)
      console.log(`   ğŸ¤– æ¨¡å‹: ${config.modelId}`)
      console.log(`\n   â±ï¸  ä¸‰å±‚è¶…æ—¶é…ç½®:`)
      console.log(`   â”Œâ”€ Layer 3 (å…œåº•): ${taskTotalTimeout}ms (${(taskTotalTimeout / 1000).toFixed(0)}ç§’)`)
      console.log(`   â”œâ”€ Layer 2a (HTTP): ${httpTimeout}ms (${(httpTimeout / 1000).toFixed(0)}ç§’) - éæµå¼ä¸“ç”¨`)
      console.log(`   â”œâ”€ Layer 2b (é¦–å­—): ${streamFirstTokenTimeout}ms (${(streamFirstTokenTimeout / 1000).toFixed(0)}ç§’) - æµå¼ä¸“ç”¨`)
      console.log(`   â””â”€ Layer 2b (ç©ºé—²): ${streamIdleTimeout}ms (${(streamIdleTimeout / 1000).toFixed(0)}ç§’) - æµå¼ä¸“ç”¨`)
      console.log(`   ğŸ”„ æœ€å¤§é‡è¯•: ${clientConfig.maxRetries}æ¬¡`)
      console.log(`   ğŸ“¡ æµå¼å“åº”: ${enableStreaming ? 'å¼€å¯' : 'å…³é—­'}`)

      // 5. åˆ›å»ºç¿»è¯‘å®¢æˆ·ç«¯
      const client = new LlmTranslationClient(clientConfig, this.llmConfigManager)
      
      // è®°å½•æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡ï¼ˆç”¨äºå–æ¶ˆåŠŸèƒ½ï¼‰
      this.executingTasks.set(taskId, client)

      // 6. Tokenä¼°ç®—ï¼ˆä¼˜å…ˆä½¿ç”¨tokenConversionConfigIdï¼Œæœªé…ç½®æ—¶ä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
      let estimatedTokens = config.predictedTokens ?? 2000 // é»˜è®¤å€¼
      
      try {
        // ä½¿ç”¨å…¬æœ‰æ–¹æ³• estimateTokensï¼ˆLlmTranslateServiceå¯¹å¤–æš´éœ²ï¼‰
        // å¦‚æœæœªé…ç½® tokenConversionConfigIdï¼Œä¼šè‡ªåŠ¨ä½¿ç”¨ default-balanced é…ç½®
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        const tokenService = this.llmTranslateService as any
        if (tokenService.estimateTokens && typeof tokenService.estimateTokens === 'function') {
          estimatedTokens = tokenService.estimateTokens(
            task.content,
            config.tokenConversionConfigId
          ) as number
          
          const configInfo = config.tokenConversionConfigId || 'default-balanced (é»˜è®¤)'
          console.log(`ğŸ”¢ [Executor] ä½¿ç”¨Tokenæ¢ç®—é…ç½® ${configInfo}: ${estimatedTokens} tokens`)
        } else {
          console.warn(`âš ï¸ [Executor] Tokenä¼°ç®—æœåŠ¡ä¸å¯ç”¨ï¼Œä½¿ç”¨é¢„è®¾å€¼`)
          estimatedTokens = config.predictedTokens ?? 2000
        }
      } catch (error) {
        console.warn(`âš ï¸ [Executor] Tokenä¼°ç®—å¤±è´¥ï¼Œä½¿ç”¨é¢„è®¾å€¼: ${error instanceof Error ? error.message : String(error)}`)
        estimatedTokens = config.predictedTokens ?? 2000
      }

      // 7. æ„å»ºç¿»è¯‘è¯·æ±‚
      const request: TranslationRequest = {
        taskId,
        content: task.content,
        estimatedTokens
      }

      // 8. æ›´æ–°çŠ¶æ€ä¸º sending
      await this.taskStateManager.updateState(taskId, 'sending')

      // 9. æ‰§è¡Œç¿»è¯‘ï¼ˆLayer 3 ä»»åŠ¡æ€»è¶…æ—¶ + Layer 2 å…·ä½“è¶…æ—¶ï¼‰
      // Layer 3: ä»»åŠ¡æ€»è¶…æ—¶ï¼ˆå…œåº•æœºåˆ¶ï¼Œä¸ç¿»è¯‘è¿‡ç¨‹ç«é€Ÿï¼‰
      const taskTimeoutPromise = new Promise<never>((_, reject) => {
        setTimeout(() => {
          reject(new Error('TIMEOUT: ä»»åŠ¡æ€»è¶…æ—¶ï¼ˆå…œåº•ï¼‰'))
        }, taskTotalTimeout)
      })

      // ç¿»è¯‘æ‰§è¡Œ Promiseï¼ˆæ ¹æ® enableStreaming é€‰æ‹©æµå¼æˆ–éæµå¼ï¼‰
      const translationPromise = (async (): Promise<TranslationResult> => {
        if (enableStreaming) {
          // æµå¼æ¨¡å¼ï¼ˆLayer 2b è¶…æ—¶å·²ä¼ é€’ç»™ clientï¼‰
          return await client.translateStream(request, {
            onStart: (id) => {
              console.log(`ğŸš€ [Executor] ä»»åŠ¡ ${id} å¼€å§‹ç¿»è¯‘ï¼ˆæµå¼ï¼‰`)
            },
            onProgress: (id, chunk, tokens) => {
              // æ›´æ–°è¿›åº¦ï¼ˆTaskStateManager ä¼šè‡ªåŠ¨èŠ‚æµå’ŒæŒä¹…åŒ–ï¼‰
              void this.taskStateManager.updateProgress(id, chunk, tokens)
            },
            onComplete: (id) => {
              console.log(`âœ… [Executor] ä»»åŠ¡ ${id} ç¿»è¯‘å®Œæˆ`)
            },
            onError: (id, error) => {
              console.error(`âŒ [Executor] ä»»åŠ¡ ${id} ç¿»è¯‘å¤±è´¥:`, error)
            }
          })
        } else {
          // éæµå¼æ¨¡å¼ï¼ˆLayer 2a è¶…æ—¶å·²é…ç½®åœ¨ client.timeoutï¼‰
          console.log(`ğŸš€ [Executor] ä»»åŠ¡ ${taskId} å¼€å§‹ç¿»è¯‘ï¼ˆéæµå¼ï¼‰`)
          const res = await client.translate(request)
          console.log(`âœ… [Executor] ä»»åŠ¡ ${taskId} ç¿»è¯‘å®Œæˆ`)
          return res
        }
      })()

      // ç«é€Ÿæ‰§è¡Œï¼šç¿»è¯‘ vs ä»»åŠ¡æ€»è¶…æ—¶
      const result = await Promise.race([translationPromise, taskTimeoutPromise])

      // 10. æ ‡è®°ä»»åŠ¡å®Œæˆ
      await this.taskStateManager.markComplete(taskId, {
        translation: result.translation,
        inputTokens: result.inputTokens,
        outputTokens: result.outputTokens,
        cost: result.cost,
        durationMs: result.durationMs
      })

      // 11. æ›´æ–°æ‰¹æ¬¡ç»Ÿè®¡
      await this.llmTranslateService.updateBatchStats(batchId)

    } catch (error) {
      const err = error as Error
      console.error(`âŒ [Executor] ä»»åŠ¡ ${taskId} æ‰§è¡Œå¤±è´¥:`, err)

      // æ ‡è®°ä»»åŠ¡é”™è¯¯
      const errorType = this.classifyError(err)
      await this.taskStateManager.markError(
        taskId,
        errorType,
        err.message,
        0
      )

      // æ›´æ–°æ‰¹æ¬¡ç»Ÿè®¡
      await this.llmTranslateService.updateBatchStats(batchId)
    } finally {
      // æ¸…ç†æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡
      this.executingTasks.delete(taskId)
    }
  }

  /**
   * æš‚åœæ‰¹æ¬¡
   */
  pauseBatch(batchId: string): void {
    this.pausedBatches.add(batchId)
    console.log(`â¸ï¸ [TranslationExecutor] æš‚åœæ‰¹æ¬¡ ${batchId}`)
  }

  /**
   * æ¢å¤æ‰¹æ¬¡
   */
  resumeBatch(batchId: string): void {
    this.pausedBatches.delete(batchId)
    console.log(`â–¶ï¸ [TranslationExecutor] æ¢å¤æ‰¹æ¬¡ ${batchId}`)
  }

  /**
   * è·å–æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡çš„LLMå®¢æˆ·ç«¯
   */
  getExecutingTask(taskId: string): LlmTranslationClient | undefined {
    return this.executingTasks.get(taskId)
  }

  /**
   * å–æ¶ˆæ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡
   */
  cancelTask(taskId: string): void {
    const client = this.executingTasks.get(taskId)
    if (client) {
      client.cancel()
      console.log(`âœ‚ï¸ [TranslationExecutor] å·²å–æ¶ˆä»»åŠ¡ ${taskId}`)
    }
  }

  /**
   * é”™è¯¯åˆ†ç±»ï¼ˆæ‰©å±•ç‰ˆ - æ”¯æŒä¸‰å±‚è¶…æ—¶æ¶æ„ï¼‰
   * 
   * ä¼˜å…ˆçº§: ç²¾ç¡®åŒ¹é…çš„è¶…æ—¶ç±»å‹ > çŠ¶æ€ç  > å…³é”®è¯
   */
  private classifyError(error: Error): ErrorType {
    const message = error.message
    const messageLower = message.toLowerCase()
    const status = 'status' in error ? (error as { status: number }).status : undefined
    
    // 1. ä¼˜å…ˆè¯†åˆ«ä¸‰å±‚è¶…æ—¶æ¶æ„çš„é”™è¯¯ï¼ˆç²¾ç¡®åŒ¹é…é”™è¯¯æ¶ˆæ¯ï¼‰
    if (message.includes('TIMEOUT:')) {
      if (message.includes('ä»»åŠ¡æ€»è¶…æ—¶ï¼ˆå…œåº•ï¼‰')) {
        return 'TIMEOUT_TOTAL'
      }
      if (message.includes('HTTPè¯·æ±‚è¶…æ—¶ï¼ˆä¸»åŠ¨å…³é—­ï¼‰')) {
        return 'TIMEOUT_HTTP'
      }
      if (message.includes('é¦–ä¸ªtokenè¶…æ—¶ï¼ˆä¸»åŠ¨å…³é—­ï¼‰') || message.includes('ç­‰å¾…é¦–ä¸ªtokenè¶…æ—¶')) {
        return 'TIMEOUT_FIRST_TOKEN'
      }
      if (message.includes('ç©ºé—²è¶…æ—¶ï¼ˆä¸»åŠ¨å…³é—­ï¼‰') || message.includes('æµå¼å“åº”ç©ºé—²è¶…æ—¶')) {
        return 'TIMEOUT_IDLE'
      }
    }
    
    // 2. æœåŠ¡å™¨è¿æ¥å…³é—­
    if (message.includes('CONNECTION:') && message.includes('æœåŠ¡å™¨å…³é—­è¿æ¥')) {
      return 'CONNECTION_CLOSED'
    }
    
    // 3. é™æµé”™è¯¯ï¼ˆ429ï¼‰- ç‰¹æ®Šå¤„ç†
    if (status === 429 || messageLower.includes('429') || messageLower.includes('rate limit')) {
      return 'RATE_LIMIT'
    }
    
    // 4. APIé”™è¯¯ï¼ˆé429çš„å…¶ä»–HTTPé”™è¯¯ï¼‰
    if (message.includes('API_ERROR:') || (status !== undefined && status >= 400 && status !== 429)) {
      return 'API_ERROR'
    }
    
    // 5. é€šç”¨è¶…æ—¶ï¼ˆå‘åå…¼å®¹ï¼‰
    if (status === 408 || status === 504 || messageLower.includes('timeout') || messageLower.includes('econnaborted')) {
      return 'TIMEOUT'
    }
    
    // 6. è®¤è¯é”™è¯¯
    if (status === 401 || status === 403 || messageLower.includes('api key') || 
        messageLower.includes('unauthorized') || messageLower.includes('forbidden')) {
      return 'INVALID_API_KEY'
    }
    
    // 7. ç½‘ç»œé”™è¯¯
    if (messageLower.includes('network') || messageLower.includes('econnrefused') || 
        messageLower.includes('econnreset') || messageLower.includes('etimedout')) {
      return 'NETWORK'
    }
    
    // 8. æ¨¡å‹é”™è¯¯
    if (messageLower.includes('model') || messageLower.includes('invalid model') || status === 404) {
      return 'MODEL_ERROR'
    }
    
    // 9. æœåŠ¡å™¨é”™è¯¯ï¼ˆ500ã€502ã€503ç­‰ï¼‰
    if ((status !== undefined && status >= 500) || messageLower.includes('500') || 
        messageLower.includes('internal server error') || messageLower.includes('bad gateway') || 
        messageLower.includes('service unavailable') || messageLower.includes('malformed')) {
      return 'MODEL_ERROR'
    }
    
    // 10. æœªçŸ¥é”™è¯¯
    return 'UNKNOWN'
  }

  /**
   * å»¶è¿Ÿè¾…åŠ©å‡½æ•°
   */
  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms))
  }
}

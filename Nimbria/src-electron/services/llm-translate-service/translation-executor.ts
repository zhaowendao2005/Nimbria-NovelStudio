/**
 * ç¿»è¯‘æ‰§è¡Œå™¨ - Electron ä¸»è¿›ç¨‹ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†å™¨
 * 
 * èŒè´£ï¼š
 * - ç®¡ç†ä»»åŠ¡é˜Ÿåˆ—ï¼ˆFIFOï¼‰
 * - å¹¶å‘æ§åˆ¶ï¼ˆé™åˆ¶åŒæ—¶æ‰§è¡Œçš„ä»»åŠ¡æ•°ï¼‰
 * - ä¸ LlmChatService äº¤äº’è°ƒç”¨æœ¬åœ°LLMè¿›è¡Œç¿»è¯‘
 * - ç›‘å¬æµå¼å“åº”å¹¶å¹¿æ’­è¿›åº¦äº‹ä»¶
 * - é”™è¯¯æ•è·å’Œé‡è¯•é€»è¾‘
 * 
 * âš ï¸ æ‰€æœ‰æ“ä½œéƒ½åœ¨ä¸»è¿›ç¨‹æœ¬åœ°å®Œæˆï¼Œæ— å¤–éƒ¨ç½‘ç»œè°ƒç”¨
 */

import type { LlmTranslateService } from './llm-translate-service'
import type { LlmChatService } from '../llm-chat-service/llm-chat-service'
import type { TranslateConfig, ErrorType, TaskSubmittedEvent, TaskProgressEvent, TaskCompleteEvent, TaskErrorEvent } from './types'

export class TranslationExecutor {
  private llmTranslateService: LlmTranslateService
  private llmChatService: LlmChatService
  private taskQueues: Map<string, string[]> = new Map()  // batchId -> taskIds[]
  private pausedBatches: Set<string> = new Set()
  private activeTaskCount: Map<string, number> = new Map()  // batchId -> count

  constructor(llmTranslateService: LlmTranslateService, llmChatService: LlmChatService) {
    this.llmTranslateService = llmTranslateService
    this.llmChatService = llmChatService
  }

  /**
   * æ‰§è¡Œä»»åŠ¡é˜Ÿåˆ—
   * ä½¿ç”¨å¹¶å‘æ§åˆ¶ï¼Œé™åˆ¶åŒæ—¶æ‰§è¡Œçš„ä»»åŠ¡æ•°
   */
  async executeTasks(
    batchId: string,
    taskIds: string[],
    config: TranslateConfig,
    concurrency: number
  ): Promise<void> {
    this.taskQueues.set(batchId, [...taskIds])
    this.activeTaskCount.set(batchId, 0)

    console.log(`ğŸ¬ [TranslationExecutor] å¼€å§‹æ‰§è¡Œæ‰¹æ¬¡ ${batchId}ï¼Œå…± ${taskIds.length} ä¸ªä»»åŠ¡ï¼Œå¹¶å‘: ${concurrency}`)

    // å¯åŠ¨å¹¶å‘ä»»åŠ¡
    const workers: Promise<void>[] = []
    for (let i = 0; i < Math.min(concurrency, taskIds.length); i++) {
      workers.push(this.worker(batchId, config))
    }

    await Promise.all(workers)

    console.log(`âœ… [TranslationExecutor] æ‰¹æ¬¡ ${batchId} æ‰§è¡Œå®Œæˆ`)
  }

  /**
   * å·¥ä½œçº¿ç¨‹ï¼šä¸æ–­ä»é˜Ÿåˆ—å–ä»»åŠ¡å¹¶æ‰§è¡Œ
   */
  private async worker(batchId: string, config: TranslateConfig): Promise<void> {
    while (true) {
      // æ£€æŸ¥æ˜¯å¦æš‚åœ
      if (this.pausedBatches.has(batchId)) {
        console.log(`â¸ï¸ [TranslationExecutor] æ‰¹æ¬¡ ${batchId} å·²æš‚åœï¼Œå·¥ä½œçº¿ç¨‹é€€å‡º`)
        break
      }

      // ä»é˜Ÿåˆ—å–ä»»åŠ¡
      const queue = this.taskQueues.get(batchId)
      if (!queue || queue.length === 0) {
        break  // é˜Ÿåˆ—ç©ºäº†ï¼Œé€€å‡º
      }

      const taskId = queue.shift()
      if (!taskId) break

      // æ‰§è¡Œä»»åŠ¡
      await this.executeTask(batchId, taskId, config)

      // ç­‰å¾…é—´éš”ï¼ˆé˜²æ­¢é™æµï¼‰
      await this.delay(1000 / config.concurrency * 60)  // åŸºäºå¹¶å‘æ•°è®¡ç®—é—´éš”
    }
  }

  /**
   * æ‰§è¡Œå•ä¸ªä»»åŠ¡
   */
  private async executeTask(batchId: string, taskId: string, config: TranslateConfig): Promise<void> {
    const projectDb = this.llmTranslateService.getProjectDatabase()
    if (!projectDb) return

    try {
      // 1. è·å–ä»»åŠ¡
      const task = await this.llmTranslateService.getTask(taskId)
      if (!task) {
        throw new Error(`Task ${taskId} not found`)
      }

      // 2. æ›´æ–°çŠ¶æ€ä¸º waiting
      projectDb.execute(
        `UPDATE Llmtranslate_tasks 
         SET status = 'waiting', sent_time = CURRENT_TIMESTAMP, updated_at = CURRENT_TIMESTAMP 
         WHERE id = ?`,
        [taskId]
      )

      this.llmTranslateService.emit('task:submitted', {
        batchId,
        taskId,
        sentTime: new Date().toISOString()
      } as TaskSubmittedEvent)

      // 3. è°ƒç”¨ LLM è¿›è¡Œç¿»è¯‘ï¼ˆä½¿ç”¨ LlmChatServiceï¼‰
      const startTime = Date.now()
      let translationResult = ''
      let replyTokens = 0

      // åˆ›å»ºä¸´æ—¶å¯¹è¯
      const conversationId = await this.llmChatService.createConversation(config.modelId, {
        temperature: 0.7,
        maxTokens: config.predictedTokens
      })

      // å‘é€æ¶ˆæ¯
      const messageId = await this.llmChatService.sendMessage(conversationId, 
        `${config.systemPrompt}\n\n${task.content}`
      )

      // é€šè¿‡äº‹ä»¶ç›‘å¬æµå¼è¿›åº¦
      const chunkHandler = (data: { messageId: string; chunk: string; conversationId: string }) => {
        if (data.conversationId === conversationId && data.messageId === messageId) {
          translationResult += data.chunk
          replyTokens = this.estimateTokens(translationResult)
          
          const progress = Math.min((replyTokens / task.predictedTokens) * 100, 100)

          // å‘å°„è¿›åº¦äº‹ä»¶
          this.llmTranslateService.emit('task:progress', {
            batchId,
            taskId,
            replyTokens,
            progress,
            chunk: data.chunk
          } as TaskProgressEvent)

          // æ›´æ–°æ•°æ®åº“è¿›åº¦
          try {
            projectDb.execute(
              `UPDATE Llmtranslate_tasks 
               SET reply_tokens = ?, progress = ?, updated_at = CURRENT_TIMESTAMP 
               WHERE id = ?`,
              [replyTokens, progress, taskId]
            )
          } catch (err) {
            console.error('Failed to update task progress:', err)
          }
        }
      }

      this.llmChatService.on('message:chunk', chunkHandler)

      // ç­‰å¾…å“åº”å®Œæˆ
      await new Promise<void>((resolve, reject) => {
        const completeHandler = (data: { messageId: string; conversationId: string }) => {
          if (data.conversationId === conversationId && data.messageId === messageId) {
            this.llmChatService.off('message:chunk', chunkHandler)
            this.llmChatService.off('message:complete', completeHandler)
            this.llmChatService.off('message:error', errorHandler)
            resolve()
          }
        }

        const errorHandler = (data: { messageId: string; conversationId: string; error: string }) => {
          if (data.conversationId === conversationId && data.messageId === messageId) {
            this.llmChatService.off('message:chunk', chunkHandler)
            this.llmChatService.off('message:complete', completeHandler)
            this.llmChatService.off('message:error', errorHandler)
            reject(new Error(data.error))
          }
        }

        this.llmChatService.on('message:complete', completeHandler)
        this.llmChatService.on('message:error', errorHandler)
      })

      // 4. ä»»åŠ¡å®Œæˆ
      const durationMs = Date.now() - startTime
      const cost = this.calculateCost(task.inputTokens, replyTokens)

      projectDb.execute(
        `UPDATE Llmtranslate_tasks 
         SET status = 'completed', 
             translation = ?,
             reply_tokens = ?,
             progress = 100,
             reply_time = CURRENT_TIMESTAMP,
             duration_ms = ?,
             cost = ?,
             updated_at = CURRENT_TIMESTAMP
         WHERE id = ?`,
        [translationResult, replyTokens, durationMs, cost, taskId]
      )

      // 5. å‘å°„å®Œæˆäº‹ä»¶
      this.llmTranslateService.emit('task:complete', {
        batchId,
        taskId,
        translation: translationResult,
        totalTokens: replyTokens,
        durationMs,
        cost
      } as TaskCompleteEvent)

      // 6. æ›´æ–°æ‰¹æ¬¡ç»Ÿè®¡
      await this.llmTranslateService.updateBatchStats(batchId)

      // 7. æ¸…ç†ä¸´æ—¶å¯¹è¯
      await this.llmChatService.deleteConversation(conversationId)

    } catch (error) {
      // é”™è¯¯å¤„ç†
      const errorMessage = error instanceof Error ? error.message : String(error)
      let errorType: ErrorType = 'unknown'

      if (errorMessage.includes('429') || errorMessage.includes('rate limit')) {
        errorType = 'rate_limit'
        projectDb.execute(
          `UPDATE Llmtranslate_tasks 
           SET status = 'throttled', error_type = ?, error_message = ?, updated_at = CURRENT_TIMESTAMP 
           WHERE id = ?`,
          [errorType, errorMessage, taskId]
        )
      } else if (errorMessage.includes('timeout')) {
        errorType = 'timeout'
        projectDb.execute(
          `UPDATE Llmtranslate_tasks 
           SET status = 'error', error_type = ?, error_message = ?, updated_at = CURRENT_TIMESTAMP 
           WHERE id = ?`,
          [errorType, errorMessage, taskId]
        )
      } else {
        projectDb.execute(
          `UPDATE Llmtranslate_tasks 
           SET status = 'error', error_type = 'unknown', error_message = ?, updated_at = CURRENT_TIMESTAMP 
           WHERE id = ?`,
          [errorMessage, taskId]
        )
      }

      // å‘å°„é”™è¯¯äº‹ä»¶
      this.llmTranslateService.emit('task:error', {
        batchId,
        taskId,
        errorType,
        errorMessage
      } as TaskErrorEvent)

      // æ›´æ–°æ‰¹æ¬¡ç»Ÿè®¡
      await this.llmTranslateService.updateBatchStats(batchId)
    }
  }

  /**
   * æš‚åœæ‰¹æ¬¡
   */
  pauseBatch(batchId: string): void {
    this.pausedBatches.add(batchId)
    console.log(`â¸ï¸ [TranslationExecutor] æ‰¹æ¬¡ ${batchId} å·²æš‚åœ`)
  }

  /**
   * æ¢å¤æ‰¹æ¬¡
   */
  resumeBatch(batchId: string): void {
    this.pausedBatches.delete(batchId)
    console.log(`â–¶ï¸ [TranslationExecutor] æ‰¹æ¬¡ ${batchId} å·²æ¢å¤`)
    
    // TODO: é‡æ–°å¯åŠ¨å·¥ä½œçº¿ç¨‹
  }

  /**
   * ä¼°ç®— Token æ•°
   */
  private estimateTokens(text: string): number {
    return Math.ceil(text.length / 4)
  }

  /**
   * è®¡ç®—æˆæœ¬
   */
  private calculateCost(inputTokens: number, outputTokens: number): number {
    // ç¤ºä¾‹ä»·æ ¼ï¼ˆéœ€è¦æ ¹æ®å®é™…æ¨¡å‹è°ƒæ•´ï¼‰
    const INPUT_PRICE_PER_1K = 0.03  // $0.03 per 1K tokens
    const OUTPUT_PRICE_PER_1K = 0.06 // $0.06 per 1K tokens
    
    return (inputTokens / 1000) * INPUT_PRICE_PER_1K + (outputTokens / 1000) * OUTPUT_PRICE_PER_1K
  }

  /**
   * å»¶è¿Ÿå‡½æ•°
   */
  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms))
  }
}

